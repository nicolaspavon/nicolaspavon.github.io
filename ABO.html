<!DOCTYPE html>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
  <title>ABO Image classification</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" charset="UTF-8" />
  <link rel="stylesheet" href="assets/css/main.css" />
  <noscript>
    <link rel="stylesheet" href="assets/css/noscript.css" />
  </noscript>
  <link rel="icon" href="images/icon.webp" type="image/x-icon" />
  <script>
    function showMoreCategories() {
      const groups = document.querySelectorAll('.category-group');
      groups.forEach((group, index) => {
        if (index !== 0) {
          group.style.display = 'block';
        }
      });
      document.getElementById('show-more-btn').style.display = 'none';
    }
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      const progressBars = document.querySelectorAll(".progress-bar");

      // IntersectionObserver callback function
      const animateProgressBar = (entries, observer) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const progressBar = entry.target;
            const value = parseFloat(progressBar.getAttribute("value"));
            progressBar.setAttribute("value", "0"); // Start from 0

            // Animate the progress bar value
            let currentValue = 0;
            const increment = value / 100; // Adjust this for speed
            const interval = setInterval(() => {
              currentValue += increment;
              if (currentValue >= value) {
                currentValue = value;
                clearInterval(interval);
              }
              progressBar.setAttribute("value", currentValue);
            }, 15); // Adjust this for smoothness

            // Stop observing the progress bar after animation is done
            observer.unobserve(progressBar);
          }
        });
      };

      // Create an IntersectionObserver
      const observer = new IntersectionObserver(animateProgressBar, {
        threshold: 0.1 // Trigger when 10% of the element is visible
      });

      // Observe each progress bar
      progressBars.forEach(bar => observer.observe(bar));
    });
  </script>

  <style>
    h3 {
      color: #ee5f0f;
    }

    h4 {
      font-size: 0.9em;
    }

    h5 {
      font-size: 0.8em;
    }

    .white-big {
      font-size: 1.3em;
      text-align: center;
      margin-bottom: 20px;
      border-bottom: none !important;
    }

    .orange_title {
      font-size: 1.1em;
    }

    .variable {
      /* font-family: "Courier New", Courier, monospace; */
      background-color: #212430;
      padding: 2px 4px;
      color: #ee5f0f;
      font-size: 12px;
      font-weight: bold;
    }

    .variable_2 {
      /* font-family: "Courier New", Courier, monospace; */
      background-color: #212430;
      padding: 2px 4px;
      color: #ee5f0f;
      font-size: 16px;
      font-weight: bold;
    }

    .main-image {
      margin-right: 20px;
      height: auto;
      width: 100px;
      /* Maintain aspect ratio */
      object-fit: cover;
      /* Adjust the margin value as needed */
    }

    .oth-image {
      margin-right: 20px;
      height: auto;
      width: 100px;
      /* Maintain aspect ratio */
      object-fit: cover;
      /* Adjust the margin value as needed */
    }

    .gtr-uniform {
      display: flex;
      align-items: center;
      gap: 10px;
      /* Optional: Adds a gap between all columns */
    }

    .image-fit {
      width: 100%;
      max-width: 300px;
      height: auto;
      object-fit: cover;
    }

    /* Form Container */
    #contact-form {
      background-color: #2e3141;
      padding: 40px;
      border-radius: 8px;
    }

    /* Form Fields */
    .fields {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }

    .field {
      width: 100%;
    }

    /* Half-width fields for larger screens */
    .field.half {
      width: calc(50% - 10px);
    }

    .field.half.second {
      width: calc(50% - 10px);
      padding-right: 20px;
      padding-left: 0px;
    }

    /* Input and Textarea Styling */
    input[type="text"],
    input[type="email"],
    textarea {
      width: 100%;
      padding: 12px 15px;
      border: 1px solid #ccc;
      border-radius: 4px;
      background-color: #fff;
      color: #333;
      font-size: 16px;
    }

    /* Button Styling */
    .button {
      background-color: #ee5f0f;
      color: #fff;
      padding: 12px 30px;
      border: none;
      cursor: pointer;
      border-radius: 4px;
      font-size: 16px;
      text-align: center;
      display: block;
      margin: 0 auto;
      transition: background-color 0.3s;
      line-height: 0;
    }

    .button:hover {
      background-color: #ff7043;
    }

    /* Labels */
    label {
      color: #f0f0f0;
      font-size: 14px;
      margin-bottom: 8px;
      display: block;
    }

    /* Form Responsiveness */
    @media (max-width: 768px) {
      .field.half {
        width: 100%;
      }
    }

    /* Styling for the home images container */
    .home-images {
      display: flex;
      justify-content: space-between;
      background-color: #3a3d52;
      /* Background color for the row */
      padding: 20px;
      border-radius: 8px;
    }

    /* Styling for each image container */
    .home-image {
      flex: 1;
      margin: 0 10px;
      background-color: #4b4e63;
      /* Default background color for images */
      padding: 10px;
      border-radius: 8px;
      text-align: center;
    }

    /* Styling for the main image */
    .home-image.main-image {
      background-color: #5c5f75;
      max-width: 207px;
      /* Slightly different background color */
    }

    /* Styling for the images inside the containers */
    .home-image img {
      max-width: 100%;
      height: auto;
      border-radius: 4px;
    }

    .oth-row {
      display: flex;
      gap: 10px
    }

    .generic-cat {
      display: flex;
      flex-direction: row;
    }

    .gradio {
      width: 100%;
      height: auto;
      min-height: 483px;
    }

    /* Responsive adjustments */
    @media (max-width: 768px) {
      .home-images {
        flex-direction: column;
        gap: 20px;
      }

      .generic-cat {
        display: flex;
        flex-direction: column;
      }

      .home-image {
        margin: 10px 0;
      }

    }

    /* Responsive adjustments */
    @media (max-width: 878px) {

      .gradio {
        width: 100%;
        height: auto;
        min-height: 838px;
      }
    }

    /* Progress Bar Styling */
    .progress-bar {
      width: 100%;
      height: 8px;
      appearance: none;
      -webkit-appearance: none;
      margin-bottom: 5px;
    }

    /* Custom styles for different browsers */
    .progress-bar::-webkit-progress-bar {
      background-color: #f0f0f0;
      border-radius: 4px;
    }

    .progress-bar::-webkit-progress-value {
      background-color: #fe8d59;
      border-radius: 4px;
    }

    .progress-bar::-moz-progress-bar {
      background-color: #fe8d59;
      border-radius: 4px;
    }

    .category-group {
      margin-bottom: 20px;
    }

    #show-more-btn {
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 11px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
    }

    #show-more-btn:hover {
      background-color: #ff7043;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-family: Arial, sans-serif;
    }

    th,
    td {
      padding: 10px;
      text-align: center;
      border: 2px solid #666;
      font-weight: 600;
      /* Make text slightly bolder */
    }

    th {
      background-color: #2e3141;
      color: #ee5f0f;
      border-bottom: 3px solid #ee5f0f;
    }


    td.boolean-cell {
      font-size: 1.5em;
    }

    td.accuracy,
    td.loss,
    td.val_accuracy,
    td.val_loss {
      width: 70px;
      color: #fff;
      /* Ensure text contrast on colored background */
    }

    .green-check {
      color: #66bb6a;
    }

    .red-cross {
      color: #ff7043;
    }

    .separator {
      border: none;
      width: 1px;
    }

    td.separator {
      background-color: #2e3141;
      /* Set a consistent color for the separator column */
      border: none;
      /* Remove the border for the separator column */
    }

    tr:nth-child(odd) {
      background-color: #3a3b44;
      /* Softer color for odd rows */
    }

    tr:nth-child(even) {
      background-color: #404351;
      /* Slightly darker, but still subtle */
    }

    th,
    td {
      padding: 5px;
      /* Reduce padding to make rows less tall */
      text-align: center;
      border: 2px solid #666;
      font-weight: 600;
      /* Keep the bold text */
    }

    td.accuracy,
    td.loss,
    td.val_accuracy,
    td.val_loss {
      padding: 8px;
      /* Slightly larger padding for the score cells for readability */
    }

    tbody tr {
      height: 40px;
      /* Adjust this value to your preferred fixed row height */
    }

    td {
      vertical-align: middle;
      overflow: hidden;
      /* Prevent overflow from expanding the row */
      white-space: nowrap;
      /* Prevent text wrapping inside the cells */
      text-overflow: ellipsis;
      /* Add ellipsis if the text is too long */
    }

    table td {
      padding: 0em 0.35em;
    }

    table th {
      padding: 5px;
    }
  </style>
</head>

<body class="is-preload" style="
      background-image: linear-gradient(
          to top,
          rgba(46, 49, 65, 0.8),
          rgba(46, 49, 65, 0.8)
        ),
        url(images/ABO/cosas.webp);
    ">
  <!-- Page Wrapper -->
  <div id="page-wrapper">
    <!-- Header -->
    <header id="header">
      <a href="index.html">
        <h1>Nicol√°s Pav√≥n</h1>
      </a>
      <nav>
        <a href="ABO-eng.html">ENG</a>
        <a href="#menu">Men√∫</a>
      </nav>
    </header>

    <!-- Menu -->
    <nav id="menu"></nav>

    <!-- Wrapper -->
    <section id="wrapper">
      <header id="ABO-header">
        <div class="inner">
          <h2>Clasificando imagenes de Amazon</h2>
        </div>
      </header>

      <!-- Content -->
      <div class="wrapper">
        <div class="inner">
          <section>
            <h3 class="orange_title major">El problema</h3>
            <p>
              En los √∫ltimos 20 a√±os, el E-Commerce ha crecido exponencialmente. Basta con solo observar el poder y
              tama√±o de los sitios como Amazon, Alibaba o incluso Mercado Libre para darse cuenta de la importancia que
              tienen al d√≠a de hoy. A partir de esto, podemos concluir que si hay algo que tienen estos gigantes de la
              inform√°tica son muchos datos, y entre ellos, muchas im√°genes. Sin embargo, los datos no sirven para nada
              si no se pueden interpretar y trabajar, por lo que ser√≠a √∫til poder clasificarlos para poder darles un uso
              apropiado y sacarles todo el provecho posible.
            </p>

            <h3 class="orange_title major">Los datos</h3>
            <p>

              Entre todos los datasets disponibles, nos topamos con uno
              <i>interesante</i>, el
              <a href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">Amazon Berkeley Objects (ABO)
                Dataset.</a> Este dataset nos provee im√°genes de aproximadamente 147,000 productos de Amazon, con su
              correspondiente metadata que incluye su categor√≠a, color, palabras clave, marca, nombre, modelo, etc.
              Adem√°s, provee renders en 3D y algunos otros detalles interesantes. Si bien no hemos explorado a√∫n los
              datos en profundidad para determinar su pureza, apreciamos el hecho de que provienen de Amazon, por lo que
              las im√°genes son ideales para este problema.
            </p>

            <h3 class="orange_title major">La tecnolog√≠a</h3>
            <p>
              Si bien para este tipo de problemas hoy en d√≠a suelen utilizarse los transformers, en este caso
              utilizaremos
              redes convolucionales, partiendo de un modelo preentrenado como inception-v3 y aplicando transfer
              learning, donde quitaremos las capas superiores de clasificaci√≥n y a√±adiremos nuevas capas especializadas
              para esta tarea. Por √∫ltimo, aplicaremos fine-tuning para mejorar la performance. El c√≥digo fue
              desarrollado en Google Colab.
            </p>

            <h3 class="orange_title major">El objetivo</h3>
            <p>
              Como objetivo nos interesa poder clasificar el producto en la imagen, dando por hecho que la imagen
              corresponde a un producto de e-commerce. Tomando esto en cuenta y analizando el dataset, observamos la
              propiedad <i class="variable">product_type</i>, la cual tiene alrededor de 574 clases que var√≠an en nivel
              de precisi√≥n, desde
              ‚ÄúRING‚Äù hasta ‚ÄúBISS‚Äù (Business, Industrial, and Scientific Supplies). Partiremos de esta propiedad del
              dataset para entrenar nuestro modelo.
            </p>
          </section>
        </div>
      </div>
      <div class="wrapper alt style4">
        <div class="inner">
          <section>
            <h2 class="white-big major">Informacion y estructura del dataset</h2>
            <h3 class="orange_title major">Estructura del dataset</h3>
            <p>
              <a href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">El dataset</a>
              cuenta con varios archivos para descargar, de los cuales nos interesan <i
                class="variable">listings.tar</i>
              (Listado de productos y metadata) y <i class="variable">images-small.tar</i>
              (catalogo de imagenes re escaladas a un maximo de 256 pixeles).
              <br /><br />
              El archivo <i class="variable">listings.tar</i> contiene 15 archivos .json, cada uno conteniendo una lista
              de objetos, siendo cada objeto un producto de amazon. Utilizaremos un script para pasar la informacion
              relevante de estos objetos a archivos .csv, para que sean mas c√≥modos de trabajar.
              Los objetos tienen una serie de atributos, de los cuales nos interesar√° <b><i>item_id</i></b> , <b>
                <i>product_type</i></b> , <b> <i>main_image_id</i></b> y <b><i>other_image_id</i></b>
            </p>
            <h3 class="orange_title major">Atributos del dataset y estadisticas</h3>
            <p>
              Una vez que tenemos el .CSV inicial, procedemos a observar la distribucion de las clases:
            </p>

            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS inicial desb.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset inicial</i></p>
              </span>
            </div>

            <p>Como se ve en la imagen, el dataset est√° totalmente desbalanceado, con muchos ejemplos para ciertas
              categor√≠as y casi ninguno en otras. Observando los datos en detalle, vemos que hay 574 categor√≠as, de las
              cuales 460 tienen menos de 100 ejemplos. Esto es un problema ya que necesitamos una buena cantidad de
              im√°genes por categor√≠a para poder identificar ese tipo de objetos con √©xito.. y solo 100 o menos no son
              suficientes. ü´†</p>
            <p>
              Para lidiar con este problema, utilizaremos el cl√°sico divide y vencer√°s, y trabajaremos solo con las
              categor√≠as que tengan m√°s ejemplos, balanceando los mismos para que no haya sesgos entre las categor√≠as a
              la hora de entrenarlos. Originalmente se opt√≥ por trabajar con 170 categor√≠as, con al menos 50
              ejemplos por categoria. Esto no
              di√≥ resultado, por lo que se reduci√≥ el dataset a todas las categor√≠as que tengan al menos 150 ejemplos, y
              con un tope de 400. Esta fue una decisi√≥n un tanto arbitraria, por lo
              que, si se vuelve necesario, es posible encontrar una mejor selecci√≥n de categor√≠as/ejemplos.
            </p>
            <p style="margin-bottom: 10px;">Una vez realizados los filtros, podemos observar las
              estadisticas del datset final:
            </p>

            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS min 150 max 400.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset simplificado</i></p>
              </span>
            </div>

            <p>En este dataset tenemos 80 categorias, mucho mejor balanceadas que las 574 del dataset inicial. Esto
              facilitar√° el trabajo ya que la red neuronal final ser√° mas facil de entrenar, y tendr√° un promedio de
              ejemplos por categor√≠a bastamente mayor
            </p>

            <h3 class="orange_title major">Inspecci√≥n del dataset</h3>
            <p>
              En este paso analizaremos el dataset previamente refinado en busca de posibles problemas evidentes a la
              vista, entre los cuales encontramos:
            <h5>Categorias confundibles: </h5>
            <p>Estas categorias tienen objetos muy similares entre s√≠. Incluso en algunos casos la unica forma de
              diferenciarlos es leyendo el texto de los mismos. Esto es un problema ya que para la red neuronal ser√°
              dificil decidir la categoria.</p>
            <ul>
              <li><i class="variable">ACCESORY</i> &#8596; <i class="variable">HAT</i></li>
              <li><i class="variable">STORAGE_HOOK</i> &#8596; <i class="variable">TOOLS</i></li>
              <li><i class="variable">NUTRITIONAL_SUPLEMENT</i> &#8596; <i class="variable">VITAMINS</i> &#8596; <i
                  class="variable">HEALTH_PERSONAL_CARE</i></li>
              <li><i class="variable">LUGGAGE</i> &#8596; <i class="variable">SUIT_CASE</i></li>
              <li><i class="variable">FINERING</i> &#8596; <i class="variable">RING</i></li>
              <li><i class="variable">FINENECKLACEBRACALETANKLET</i> &#8596; <i class="variable">NECKLACE</i></li>
              <li><i class="variable">FINEEARING</i> &#8596; <i class="variable">EARRING</i></li>
            </ul>
            <p>Exceptuando los casos de 'fine x' &#8596;
              'x', en un principio conservaremos estas categorias y observaremos si son efectivamente
              problematicas al momento de clasificar.
              Para los casos 'fine x' nos quedaremos con los que no son "fine", ya que son m√°s abarcativos y siguen
              preservando la forma general.</p>

            <h5>Categorias genericas: </h5>
            <p>Estas categorias tienen objetos muy variados, por lo que ser√° mas dificil entrenar a la red en busca de
              patrones similares. Si todos los objetos de una categoria varian en forma, no existe un set de features
              /
              patrones que los unifique y la red no podr√° categorizar eficientemente. Solo seria posible lograrlo si
              cada sub tipo de objeto en esta
              categoria tuviese suficientes imagenes, pero como quizas de 400 imagenes, solo 90 pertenecen a uno de
              estos objetos, sera muy dificil de entrenar. Por esta razon estas categorias ser√°n quitadas del dataset.
            </p>
            <div class="generic-cat">
              <ul>
                <li><i class="variable">HOME</i></li>
                <li><i class="variable">WIRELESS_ACCESORY</i></li>
                <li><i class="variable">ACCESORY_OR_PART_OR_SUPPLY</i></li>
                <li><i class="variable">BABY_PRODUCT</i></li>
                <li><i class="variable">COMPUTER_ADDON</i></li>
                <li><i class="variable">GROCERY</i></li>
                <li><i class="variable">SPORTING_GOODS</i></li>
                <li><i class="variable">PANTRY</i></li>
                <li><i class="variable">KITCHEN</i></li>
                <li><i class="variable">JANITORY_SUPPLY</i></li>
                <li><i class="variable">HOMEFURNITURE_AND_DECOR</i></li>
                <li><i class="variable">HARDWARE</i></li>
              </ul>

              <div class="gtr-uniform home-images"
                style="flex-direction: column; align-items: flex-start; margin-bottom: 20px; margin-left: 16px; flex: 1; min-width: 0;">
                <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Ejemplos de productos en la categoria
                  <i class="variable">HOME</i>
                </h5>
                <div style="flex-direction: row; display: flex;">
                  <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                    <div class="oth-row">
                      <span>
                        <img src="images/ABO/HOME_3.jpg" alt="Home product example 2" />
                      </span>
                      <span>
                        <img src="images/ABO/HOME_2.jpg" alt="Home product example 1" />
                      </span>
                      <span>
                        <img src="images/ABO/HOME_1.jpg" alt="Home product example 1" />
                      </span>
                    </div>
                    <p style="margin: 0px;"><i>(No se parecen en nada)</i></p>
                  </div>
                </div>
              </div>
            </div>

            </p>
            <h3 class="orange_title major">Balanceo del dataset</h3>
            <p>
              Como se coment√≥ previamente, un posible problema es el sesgo que puede generar el desbalance de ejemplos
              a
              la hora de entrenar una red neuronal. Si en nuestra red tenemos mil ejemplos de zapatos, y cien ejemplos
              de
              sillones, para la red las probabilidades de recibir un zapato son 10 veces mayores que las de recibir un
              sillon, y siendo este el caso la red podr√≠a retornar siempre zapato, acertando la mayor√≠a de las veces.
              Esto
              afectar√≠a la clasificacion de forma bastante dr√°stica, por lo que nos interesa tener el dataset lo mas
              balanceado posible.
              En nuestro caso tenemos varias categorias con menos de 400 ejemplos, que es el numero ideal que queremos
              mantener en todas las categorias. Para lograr el balance deseado, tomaremos en cuenta las "other images"
              disponibles por
              cada objeto. Estas im√°genes pueden
              ayudarnos a completar la cantidad de imagenes para aquellas categorias que lo necesitan.
            </p>
            <h5>Ejemplos satisfactorios</h5>
            <p>Luego de una no muy breve inspeccion, observamos casos satisfactorios en los que las "other_images" son
              suficientemente similares (pero no identicas) al producto original</p>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">SOFA</i></h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <img src="images/ABO/SOFA_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/SOFA_OTH_3.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/SOFA_OTH_1.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/SOFA_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <h5>Ejemplos problematicos</h5>
            <p>Sin embargo, tambi√©n observamos imagenes que no son del producto en si, sino de una tabla descriptiva,
              un
              color, o de una toma general en la que el objeto casi es indistinguible.</p>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">LEGUME</i></h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image" style="max-width: 170px;">
                  <span>
                    <img src="images/ABO/LEGUME_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/LEGUME_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_4.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">RUG</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <img src="images/ABO/RUG_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/RUG_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/RUG_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/RUG_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <p>Estos casos nos perjudican. Nos interesa tener cierta varianza en las imagenes para que nuestra red se
              vuelva mas robusta, pero cuando tenemos imagenes muy complejas, o que nisiquiera tienen al objeto en si,
              perjudica el entrenamiento de la red, ya que la red asociara patrones erroneos a la categoria en
              cuesti√≥n. Recuerda el ejemplo de <i class="variable">RUG</i>! va a ser un problema en el futuro.
            </p>
            <p>Para superar este problema, haremos un filtrado de las "other_images" utilizando redes neuronales pre
              entrenadas. En este caso utilizaremos el modelo VGG16, quitando las capas de
              clasificacion. Esto nos dejar√° una red que solo detecta features en una
              imagen, pero no la clasifica.
              Con esta red procederemos a extraer las features de la imagen principal de cada objeto
              (main_image), y luego haremos una comparaci√≥n con las features de cada una de las "other_images" de este
              objeto, obteniendo un coeficiente de similitud entre las mismas. Este coeficiente nos indicar√° que tan
              similares son las "other_images" a la imagen principal, d√°ndole un valor muy bajo a aquellas que no
              sean similares.
            </p>
            <p style="margin-bottom: 10px;">Aqui observamos algunos ejemplos del uso de esta t√©cnica:</p>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">SOFA</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>

                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/SOFA_MAIN.jpg" alt="" />
                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
              display: flex;
              flex-direction: column;
              height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                    
                      margin: 0px;
                      margin-bottom: -9px;
                      font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.861</i></p>
                      <progress value="0.8615963" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.640</i></p>
                      <progress value="0.6404396" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.599</i></p>
                      <progress value="0.5996146" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.196</i></p>
                      <progress value="0.1969997" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_4.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">OTTOMAN</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>

                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/OTTOMAN-MAIN.jpg" alt="" />
                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
              display: flex;
              flex-direction: column;
              height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                    
                      margin: 0px;
                      margin-bottom: -9px;
                      font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.819</i></p>
                      <progress value="0.819" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.8198348.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.689</i></p>
                      <progress value="0.689" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.6890952.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.581</i></p>
                      <progress value="0.581" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.5811923.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.192</i></p>
                      <progress value="0.19274572" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.19274572.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>

            <p style="margin-bottom: 10px;">Genial! vemos que funciona, sin embargo encontramos algunos problemas:</p>
            <p>La categoria RUG nos complica un poco. Si observamos algunos ejemplos veremos que la "main_image"
              suele contener a la alfombra en una escena generica, un poco "escondida", esto causa que el coeficiente de
              similitud de las "other_images" sea muy bajo, dejando afuera muchas imagenes utiles.</p>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">RUG</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/RUG-MAIN-SIM.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.273</i></p>
                      <progress value="0.27311817" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.27311817.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.213</i></p>
                      <progress value="0.21372926" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.21372926.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.187</i></p>
                      <progress value="0.18717194" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.18717194.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <p>Utilizaremos un threshold de 0.5 como criterio para seleccionar las other_images, seleccionando aquellas
              que
              tengan un coeficiente de similitud mayor a este para completar las im√°genes faltantes en una categor√≠a,
              pero en el caso de la categor√≠a <i class="variable">RUG</i> tomaremos un threshold de solo 0.2, ya que
              sino, por las caracteristicas de las main_images, la mayor√≠a de las other_images quedar√≠an afuera.
            </p>

            <h3 class="orange_title major">Dataset final</h3>
            <p>
              Por ultimo para terminar de armar el dataset y poder entrenar la red neuronal, debemos organizar las
              im√°genes, agrupandolas por categoria.
              Una vez que sabemos los similarity scores de las other_images, procedemos a mover todas las "main images"
              a la carpeta de su categoria, y completamos aquellas que tengan pocos
              ejemplos con las other_images que tengan mayor similarity score.
            </p>
            <p style="margin-bottom: 10px;">
              Este es el balance del dataset resultante, mucho mejor!
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS FINAL.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset final</i></p>
              </span>
            </div>
            <p>
              Este dataset cuenta con 65 categor√≠as y 25800 im√°genes aproximadamente. Reconocemos que hay categorias que
              no llegaron a 400 por falta de im√°genes con un buen similarity score, pero como siguen teniendo una buena
              cantidad (>320) simplemente lo vamos a ignorar.
            </p>
            <p style="margin-bottom: 10px;">
              Las categorias finales son:
            </p>
            <div class="categories-container" style="display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 40px;">
              <!-- Categor√≠as comunes diarias -->
              <div class="category-group" style="width: 100%;">
                <i class="variable_2">COFFEE</i>
                <i class="variable_2">TEA</i>
                <i class="variable_2">BREAD</i>
                <i class="variable_2">DRINKING_CUP</i>
                <i class="variable_2">HEADPHONES</i>
                <i class="variable_2">CHARGING_ADAPTER</i>
                <i class="variable_2">SHOES</i>
                <i class="variable_2">PILLOW</i>
                <i class="variable_2">CHAIR</i>
                <i class="variable_2">WALL_ART</i>
                <i class="variable_2">LAMP</i>
                <i class="variable_2">RING</i>
                <i class="variable_2">HAT</i>
                <i class="variable_2">BACKPACK</i>
                <i class="variable_2">SUITCASE</i>
                <i class="variable_2">PLANTER</i>
                <i class="variable_2">WALLET</i>
              </div>

              <button id="show-more-btn" onclick="showMoreCategories()" style="margin-top: -20px;">...ver m√°s</button>

              <!-- Comida y Salud -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Comida y Salud</h5>
                <i class="variable_2">LEGUME</i>
                <i class="variable_2">HERB</i>
                <i class="variable_2">HEALTH_PERSONAL_CARE</i>
                <i class="variable_2">SKIN_CLEANING_AGENT</i>
                <i class="variable_2">SKIN_MOISTURIZER</i>
                <i class="variable_2">BEAUTY</i>
                <i class="variable_2">VITAMIN</i>
                <i class="variable_2">NUTRITIONAL_SUPPLEMENT</i>
              </div>

              <!-- Muebles -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Muebles</h5>
                <i class="variable_2">SHELF</i>
                <i class="variable_2">CABINET</i>
                <i class="variable_2">DESK</i>
                <i class="variable_2">TABLE</i>
                <i class="variable_2">HEADBOARD</i>
                <i class="variable_2">BED</i>
                <i class="variable_2">OTTOMAN</i>
                <i class="variable_2">STOOL_SEATING</i>
                <i class="variable_2">SOFA</i>
              </div>

              <!-- Decoraci√≥n y Ropa de Cama -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Decoraci√≥n y Ropa de Cama</h5>
                <i class="variable_2">RUG</i>
                <i class="variable_2">FLAT_SHEET</i>
                <i class="variable_2">FURNITURE_COVER</i>
                <i class="variable_2">LIGHT_FIXTURE</i>
              </div>

              <!-- Accesorios y Joyas -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Accesorios y Joyas</h5>
                <i class="variable_2">NECKLACE</i>
                <i class="variable_2">EARRING</i>
                <i class="variable_2">ACCESSORY</i>
                <i class="variable_2">HANDBAG</i>
                <i class="variable_2">BOOT</i>
                <i class="variable_2">SANDAL</i>
                <i class="variable_2">PORTABLE_ELECTRONIC_DEVICE_COVER</i>
                <i class="variable_2">CELLULAR_PHONE_CASE</i>
                <i class="variable_2">SCREEN_PROTECTOR</i>
              </div>

              <!-- Art√≠culos de Oficina y Limpieza -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Art√≠culos de Oficina y Limpieza</h5>
                <i class="variable_2">OFFICE_PRODUCTS</i>
                <i class="variable_2">STORAGE_BINDER</i>
                <i class="variable_2">STORAGE_HOOK</i>
                <i class="variable_2">CLEANING_AGENT</i>
                <i class="variable_2">BATTERY</i>
              </div>

              <!-- Otros -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Otros</h5>
                <i class="variable_2">AUTO_ACCESSORY</i>
                <i class="variable_2">TOOLS</i>
                <i class="variable_2">SAFETY_SUPPLY</i>
                <i class="variable_2">FOOD_SERVICE_SUPPLY</i>
                <i class="variable_2">BISS</i>
                <i class="variable_2">LIGHT_BULB</i>
                <i class="variable_2">OUTDOOR_LIVING</i>
                <i class="variable_2">PET_SUPPLIES</i>
              </div>
            </div>
          </section>
        </div>
      </div>

      <div class="wrapper style3">
        <div class="inner">
          <section>
            <h2 class="white-big major">Dise√±o y entrenamiento de la red neuronal</h2>
            <h3 class="orange_title major">Entrenamiento de la red</h3>
            <p>Lograr que la red tenga una buena performance fue dificil. Como se mencion√≥ previamente, se opt√≥ por
              aplicar transfer learning, partir de un modelo pre entrenado sin sus top layers (las capas de
              clasificaci√≥n). Este modelo ser√≠a el encargado de detectar las "features" en las im√°genes, y luego sobre
              esto se agregar√≠an layers custom
              encargadas de clasificar estas features dentro de las 65 categorias posibles. Por ultimo se aplicaria
              fine-tunning
              para optimizar la performance.
            </p>
            <p>En un principio se opt√≥ por utilizar el modelo VGG-16, agregando varias layers arriba
              para la clasificaci√≥n (3 dense layers, 1 dropouts). Este modelo ten√≠a muy mala
              performance.</p>
            <p>Se opt√≥ por simplificar el problema reduciendo la cantidad de categorias, y
              adem√°s pasar a utilizar inception-v3. Aqu√≠ se empezaron a notar mejoras, sobre todo cuando se simplific√≥
              la etapa de clasificaci√≥n, reduci√©ndola a 2 dense layers, 1 dropouts y 1 BatchNormalization.</p>
            <p>Luego de varias iteraciones se lograron m√©tricas satisfactorias. El modelo mas performante solo agrega
              una capa
              dense de solo 256 unidades, acompa√±ada de un Dropout(0.4) y una layer de data augmentation con varias
              tecnicas para evitar overfitting. Sorprendentemente, esta red tan sencilla es
              de las mas performantes. Por esto podemos asumir que el modelo inception-v3 ya hace un excelente trabajo
              al detectar las features en una im√°gen, dej√°ndonos poco trabajo para completar el modelo.</p>
            <p>Una vez que encontramos un dise√±o de red eficiente, continuamos con las pruebas, estudiando qu√© beneficia
              al modelo y qu√© lo perjudica. En la siguiente tabla se pueden observar las m√©tricas de los distintos
              dise√±os experimentados:</p>

            <div class="gtr-uniform home-images"
              style="margin-bottom: 10px; flex-direction: column; align-items: flex-start; background-color: #313345">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Tabla comparativa de los modelos</h5>
              <table id="score-table" style="margin: 0px">
                <thead>
                  <tr>
                    <th>Version</th>
                    <th>Dense Layers</th>
                    <th>Data <br>Augmentation</th>
                    <th>BatchNorm</th>
                    <th>Dropout</th>
                    <th class="separator"></th>
                    <th>Accuracy</th>
                    <th>Loss</th>
                    <th>Val Accuracy</th>
                    <th>Val Loss</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="description">v1.1</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.89</td>
                    <td class="loss">0.35</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.48</td>
                  </tr>
                  <tr>
                    <td class="description">v1.2</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚ùå</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.97</td>
                    <td class="loss">0.09</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.56</td>
                  </tr>
                  <tr>
                    <td class="description">v1.3</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚ùå</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.91</td>
                    <td class="loss">0.26</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.46</td>
                  </tr>
                  <tr>
                    <td class="description">v1.4</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚ùå</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.95</td>
                    <td class="loss">0.15</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.51</td>
                  </tr>
                  <tr>
                    <td class="description">v2.1</td>
                    <td>1x(256) 1x(512)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.83</td>
                    <td class="loss">0.57</td>
                    <td class="val_accuracy">0.84</td>
                    <td class="val_loss">0.54</td>
                  </tr>
                  <tr>
                    <td class="description">v2.2</td>
                    <td>1x(512) 1x(1024)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.85</td>
                    <td class="loss">0.47</td>
                    <td class="val_accuracy">0.84</td>
                    <td class="val_loss">0.55</td>
                  </tr>
                  <!-- Add more rows as needed -->
                </tbody>
              </table>
              <p style="margin-bottom: 0px; margin-top: 0px;"><i style="font-size: 14px">Todos los modelos fueron
                  entrenados con 20 epochs en el
                  entrenamiento inicial y 15 en la etapa de
                  fine-tunning</i></p>
              </span>
            </div>
            <p> Analizando un poco estas estadisticas podemos observar en los modelos v1.2 y v1.4 grandes mejoras en
              los valores de accuracy y loss, pero a la vez notamos valores de val_loss un poco peores, esto nos
              indica overfitting, lo cual tiene sentido. La layer de data augmentation busca volver a nuestro modelo
              mas robusto, alterando las im√°genes de varias formas, con rotaciones random, cambios en el contraste o
              brightness, random zooms, etc. A su vez, el mero objetivo de las capas dropout es prevenir el
              overfitting, por lo que es entendible que empeore su performance. </p>

            <p> Por otra parte, observamos que el modelo v1.3, que carece de la layer BatchNormalization y tiene una
              mejora interesante en la performance. Si bien este tipo de layers son muy importantes y frecuentemente
              utilizadas en modelos de clasificaci√≥n de im√°genes, podemos atribuir esta baja en la performance al
              hecho de que se est√° utilizando en la etapa final de clasificaci√≥n del modelo. Quiz√°s ser√≠a mas util en
              una etapa intermedia de un modelo mas complejo. </p>

            <p>Otro hecho interesante que podemos observar de las estad√≠sticas es la similitud de performances entre
              modelos respecto al val_accuracy. Como podemos ver, todos los modelos tienen valores muy similares. Mi
              teor√≠a es que esto se debe a que varias im√°genes utilizadas para la validaci√≥n simplemente est√°n
              mal, son casos similares a los de la categoria RUG, donde la primer im√°gen adem√°s de contener la
              alformbra, tambien suele contener otros objetos como sillones, sillas, cuadros, etc.
              Teniendo esto en cuenta, podemos suponer que el modelo nunca ser√° capaz de superar cierta performance,
              porque algunas im√°genes estarian clasificadas bajo cierta categoria, pero tienen objetos de otra. Esto
              es un punto a estudiar y mejorar </p>

            <p>
              Por ultimo, observamos que aumentar la complejidad del modelo solo empeora la performance, lo cual es en
              parte sorprendente, pero por otro lado tiene sentido, ya que el modelo base inception_v3 es muy bueno
              haciendo su trabajo, y posiblemente el output del mismo no pueda ser mejorable, dejandonos con la unica
              tarea de clasificar las features en las x categorias de nuestro problema.
            </p>

            <h3 class="orange_title major">Estad√≠sticas del modelo seleccionado</h3>
            <p style="margin-bottom: 20px">
              El modelo ganador fue el v1.3, en el colab se puede observar el codigo completo, explicado en detalle,
              recomiendo darle una vichada. A continuaci√≥n se observan algunas estad√≠sticas del modelo:
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 25px; background-color: #313345">
              <span class=" image fit" style="margin: 0px;">
                <h5 style="margin: 0px; margin-left: 7px; margin-bottom: 15px;">Entrenamiento inicial</h5>
                <img src="images/ABO/train v1.3.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 19px;">
                  A diferencia de los otros modelos, para entrenar este se aument√≥ de 20 epochs a 40 para exprimir un
                  poco
                  mas de performance.
                </p>
              </span>
            </div>
            <div class="gtr-uniform home-images" style="margin-bottom: 50px; background-color: #313345">
              <span class=" image fit" style="margin: 0px;">
                <h5 style="margin: 0px; margin-left: 7px; margin-bottom: 15px;">Fine tunning</h5>
                <img src="images/ABO/fine v1.3.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 19px;">
                  De igual forma se aumentaron los epochs en la etapa de fine tunning a 25, aunque como se puede
                  observar en
                  el gr√°fico, a partir del epoch 10-15 se empiezan a notar signos de overfitting, con poca mejora en los
                  valores de val_accuracy y val_loss, que son los que nos interesan
                </p>
              </span>
            </div>

            <h3 class="orange_title major">Modelo en acci√≥n</h3>
            <p>Se cre√≥ un space en HuggingFace spaces para tener el modelo activo utilizando Gradio de forma constante,
              para
              poder ser utilizado en cualquier momento. Lo puedes usar aqu√≠ abajo, pru√©balo con una foto propia!</p>

            <p style="margin-bottom: 10px;">Estas
              son las categorias mas frecuentemente accesibles en mi opini√≥n, pero puedes fotografiar cualquier objeto
              de las categorias y probar el modelo</p>
            <div class="category-group" style="width: 100%;">
              <i class="variable_2">COFFEE</i>
              <i class="variable_2">TEA</i>
              <i class="variable_2">BREAD</i>
              <i class="variable_2">DRINKING_CUP</i>
              <i class="variable_2">HEADPHONES</i>
              <i class="variable_2">CHARGING_ADAPTER</i>
              <i class="variable_2">SHOES</i>
              <i class="variable_2">PILLOW</i>
              <i class="variable_2">CHAIR</i>
              <i class="variable_2">WALL_ART</i>
              <i class="variable_2">LAMP</i>
              <i class="variable_2">RING</i>
              <i class="variable_2">HAT</i>
              <i class="variable_2">BACKPACK</i>
              <i class="variable_2">SUITCASE</i>
              <i class="variable_2">PLANTER</i>
              <i class="variable_2">WALLET</i>
            </div>
            <div style="text-align: center;">
              <iframe src="https://nicolaspavon-amazon-classification.hf.space" frameborder="0" class="gradio"></iframe>
            </div>
          </section>
        </div>
      </div>
      <div class="wrapper alt style4">
        <div class="inner">
          <section>

            <h3 class="orange_title major">Problemas</h3>
            <p>Fotos de un living! tienen todo a la vez y re chico, alfombra sillon pillow mesa!</p>
            <p>Malditas imagenes de texturas las voy a matar a todas</p>
            <p>Furniture_cover just makes me angry so i'll remove it</p>
            <p>categorias muy genericas, las imagenes no siguen un patron. o dentro de una categoria hay varias
              "categorias" / cosas distintas</p>
            <p>categorias de frascos dificiles de diferenciar</p>
            <p>categorias suitcase y luggage identicas</p>
            <h3 class="orange_title major">things that did not work</h3>
            <p>se intento usar un modelo grande para clasificar las 65 categorias, pero tenia muy mala performance.
              Luego se intento divide y venceras, un modelo cada +- 10 categorias, pero se encontro que meterle muchos
              modelos pesados rompe el gradio
              Por ultimo se decidio modelo papa con 4 categorias usando el category cluster, y luego un submodelo para
              identificar con precision, cargando en total unicamente 2 modelos</p>
            <p>se intento pasar las imagenes a blanco y negro, ya que los colores no hacen la diferencia entre una
              categoria u otra. sin embargo no se not√≥ mejora, aunque quiz√°s fue por un error de implementaci√≥n</p>

          </section>
          <section>
            <h2 class="orange_title major">Conclusiones</h2>
            <p></p>
          </section>
          <section id="contact-form">
            <div>
              <h3 class="orange_title major">Contacto</h3>
              <form id="feedbackForm" action="https://formspree.io/f/xyzygapb" method="POST">
                <div class="fields">
                  <div class="field half">
                    <label for="name">Name</label>
                    <input type="text" name="name" id="name" placeholder="Your Name" required>
                  </div>
                  <div class="field half second">
                    <label for="email">Email</label>
                    <input type="email" name="email" id="email" placeholder="Your Email" required>
                  </div>
                  <div class="field">
                    <label for="message">Message</label>
                    <textarea name="message" id="message" rows="6" placeholder="Your Message" required></textarea>
                  </div>
                  <div class="field">
                    <button type="submit" class="button">Send Message</button>
                  </div>
                </div>
              </form>
            </div>
          </section>

        </div>
      </div>
    </section>

    <!-- Footer -->
    <section id="footer"></section>
  </div>

  <!-- Scripts -->
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/jquery.scrollex.min.js"></script>
  <script src="assets/js/browser.min.js"></script>
  <script src="assets/js/breakpoints.min.js"></script>
  <script src="assets/js/util.js"></script>
  <script src="assets/js/main.js"></script>
  <script src="scripts/menu.js"></script>
  <script src="scripts/footer.js"></script>

  <script>
    function applyColorToCell() {
      const table = document.getElementById('score-table');
      const rows = table.getElementsByTagName('tr');

      for (let i = 1; i < rows.length; i++) {
        const cells = rows[i].getElementsByTagName('td');

        const accuracy = parseFloat(cells[6].innerText);
        const loss = parseFloat(cells[7].innerText);
        const valAccuracy = parseFloat(cells[8].innerText);
        const valLoss = parseFloat(cells[9].innerText);

        // For accuracy and val_accuracy (higher is better)
        cells[6].style.backgroundColor = getGreenToRedGradient(accuracy, true);
        cells[8].style.backgroundColor = getGreenToRedGradient(valAccuracy, true);

        // For loss and val_loss (lower is better)
        cells[7].style.backgroundColor = getGreenToRedGradient(loss, false);
        cells[9].style.backgroundColor = getGreenToRedGradient(valLoss, false);
      }
    }

    function getGreenToRedGradient(value, higherIsBetter) {
      const colors = [
        { r: 0, g: 128, b: 0 },     // Green
        { r: 85, g: 170, b: 0 },    // Yellowgreen
        { r: 255, g: 255, b: 0 },   // Yellow
        { r: 255, g: 165, b: 0 },   // Orange
        { r: 255, g: 0, b: 0 },     // Red
        { r: 0, g: 0, b: 0 }        // Black
      ];

      // Adjust ratio for whether higher or lower is better
      let ratio = !higherIsBetter ? value : 1 - value;
      const step = 1 / (colors.length - 1);
      const index = Math.min(Math.floor(ratio / step), colors.length - 2);
      const color1 = colors[index];
      const color2 = colors[index + 1];

      const t = (ratio - index * step) / step;
      const r = Math.round(color1.r * (1 - t) + color2.r * t);
      const g = Math.round(color1.g * (1 - t) + color2.g * t);
      const b = Math.round(color1.b * (1 - t) + color2.b * t);

      return `rgb(${r}, ${g}, ${b}, 0.8)`; // Added opacity (0.8) to the colors
    }



    // Call the function to apply colors on page load
    applyColorToCell();
  </script>

</body>

</html>