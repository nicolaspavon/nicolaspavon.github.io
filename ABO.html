<!DOCTYPE html>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
  <title>ABO Image classification</title>
  <meta charset="utf-8" />
  <meta http-equiv="Permissions-Policy" content="camera=(self)">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" charset="UTF-8" />
  <link rel="stylesheet" href="assets/css/main.css" />
  <noscript>
    <link rel="stylesheet" href="assets/css/noscript.css" />
  </noscript>
  <link rel="icon" href="images/icon.webp" type="image/x-icon" />
  <script>
    function showMoreCategories() {
      const groups = document.querySelectorAll('.category-group');
      groups.forEach((group, index) => {
        if (index !== 0) {
          group.style.display = 'block';
        }
      });
      document.getElementById('show-more-btn').style.display = 'none';
      document.getElementById('show-more-btn-2').style.display = 'none';
    }
  </script>
  <script>
    function toggleVersion() {
      const resumed = document.querySelectorAll('.resumed');
      const extended = document.querySelectorAll('.extended');

      resumed.forEach((section) => {
        if (section.style.display === 'none' || window.getComputedStyle(section).display === 'none') {
          section.style.display = 'block';
          document.getElementById('complete-btn').style.display = 'none';
          document.getElementById('resumed-btn').style.display = 'flex';
        } else {
          section.style.display = 'none';
        }
      });

      extended.forEach((section) => {
        if (section.style.display === 'none' || window.getComputedStyle(section).display === 'none') {
          section.style.display = 'block';
          document.getElementById('resumed-btn').style.display = 'none';
          document.getElementById('complete-btn').style.display = 'flex';
        } else {
          section.style.display = 'none';
        }
      });
    }
  </script>

  <script>
    function showMoreStats() {
      const groups = document.querySelectorAll('.cat_stats');
      groups.forEach((group, index) => {
        if (index !== 0) {
          group.style.display = 'table-row';
        }
      });
      document.getElementById('show-more-table-btn').style.display = 'none';
    }
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      const progressBars = document.querySelectorAll(".progress-bar");

      // IntersectionObserver callback function
      const animateProgressBar = (entries, observer) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const progressBar = entry.target;
            const value = parseFloat(progressBar.getAttribute("value"));
            progressBar.setAttribute("value", "0"); // Start from 0

            // Animate the progress bar value
            let currentValue = 0;
            const increment = value / 100; // Adjust this for speed
            const interval = setInterval(() => {
              currentValue += increment;
              if (currentValue >= value) {
                currentValue = value;
                clearInterval(interval);
              }
              progressBar.setAttribute("value", currentValue);
            }, 15); // Adjust this for smoothness

            // Stop observing the progress bar after animation is done
            observer.unobserve(progressBar);
          }
        });
      };

      // Create an IntersectionObserver
      const observer = new IntersectionObserver(animateProgressBar, {
        threshold: 0.1 // Trigger when 10% of the element is visible
      });

      // Observe each progress bar
      progressBars.forEach(bar => observer.observe(bar));
    });
  </script>

  <style>
    .resumed {
      display: none
    }

    html {
      scroll-behavior: smooth;
    }

    h3 {
      color: #ee5f0f;
    }

    h4 {
      font-size: 0.9em;
    }

    h5 {
      font-size: 0.8em;
    }

    .white-big {
      font-size: 1.3em;
      text-align: center;
      margin-bottom: 20px;
      border-bottom: none !important;
    }

    .orange_title {
      font-size: 1.1em;
    }

    .variable {
      /* font-family: "Courier New", Courier, monospace; */
      background-color: #212430;
      padding: 2px 4px;
      color: #ee5f0f;
      font-size: 12px;
      font-weight: bold;
    }

    .variable_2 {
      /* font-family: "Courier New", Courier, monospace; */
      background-color: #212430;
      padding: 2px 4px;
      color: #ee5f0f;
      font-size: 16px;
      font-weight: bold;
    }

    .main-image {
      margin-right: 20px;
      height: auto;
      width: 100px;
      /* Maintain aspect ratio */
      object-fit: cover;
      /* Adjust the margin value as needed */
    }

    .oth-image {
      margin-right: 20px;
      height: auto;
      width: 100px;
      /* Maintain aspect ratio */
      object-fit: cover;
      /* Adjust the margin value as needed */
    }

    .gtr-uniform {
      display: flex;
      align-items: center;
      gap: 10px;
      /* Optional: Adds a gap between all columns */
    }

    .image-fit {
      width: 100%;
      max-width: 300px;
      height: auto;
      object-fit: cover;
    }

    /* Form Container */
    #contact-form {
      background-color: #2e3141;
      padding: 40px;
      border-radius: 8px;
    }

    /* Form Fields */
    .fields {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }

    .field {
      width: 100%;
    }

    /* Half-width fields for larger screens */
    .field.half {
      width: calc(50% - 10px);
    }

    .field.half.second {
      width: calc(50% - 10px);
      padding-right: 20px;
      padding-left: 0px;
    }

    /* Input and Textarea Styling */
    input[type="text"],
    input[type="email"],
    textarea {
      width: 100%;
      padding: 12px 15px;
      border: 1px solid #ccc;
      border-radius: 4px;
      background-color: #fff;
      color: #333;
      font-size: 16px;
    }

    /* Button Styling */
    .button {
      background-color: #ee5f0f;
      color: #fff;
      padding: 12px 30px;
      border: none;
      cursor: pointer;
      border-radius: 4px;
      font-size: 16px;
      text-align: center;
      display: block;
      margin: 0 auto;
      transition: background-color 0.3s;
      line-height: 0;
    }

    .button:hover {
      background-color: #ff7043;
    }

    /* Labels */
    label {
      color: #f0f0f0;
      font-size: 14px;
      margin-bottom: 8px;
      display: block;
    }

    /* Form Responsiveness */
    @media (max-width: 768px) {
      .field.half {
        width: 100%;
      }
    }

    /* Styling for the home images container */
    .home-images {
      display: flex;
      justify-content: space-between;
      background-color: #3a3d52;
      /* Background color for the row */
      padding: 20px;
      border-radius: 8px;
    }

    /* Styling for each image container */
    .home-image {
      flex: 1;
      margin: 0 10px;
      background-color: #4b4e63;
      /* Default background color for images */
      padding: 10px;
      border-radius: 8px;
      text-align: center;
    }

    /* Styling for the main image */
    .home-image.main-image {
      background-color: #5c5f75;
      max-width: 207px;
      /* Slightly different background color */
    }

    /* Styling for the images inside the containers */
    .home-image img {
      max-width: 100%;
      height: auto;
      border-radius: 4px;
    }

    .oth-row {
      display: flex;
      gap: 10px
    }

    .generic-cat {
      display: flex;
      flex-direction: row;
    }

    .gradio {
      width: 100%;
      height: auto;
      min-height: 483px;
    }

    /* Responsive adjustments */
    @media (max-width: 768px) {
      .home-images {
        flex-direction: column;
        gap: 20px;
      }

      .generic-cat {
        display: flex;
        flex-direction: column;
      }

      .home-image {
        margin: 10px 0;
      }

    }

    /* Responsive adjustments */
    @media (max-width: 878px) {

      .gradio {
        width: 100%;
        height: auto;
        min-height: 838px;
      }
    }

    /* Progress Bar Styling */
    .progress-bar {
      width: 100%;
      height: 8px;
      appearance: none;
      -webkit-appearance: none;
      margin-bottom: 5px;
    }

    /* Custom styles for different browsers */
    .progress-bar::-webkit-progress-bar {
      background-color: #f0f0f0;
      border-radius: 4px;
    }

    .progress-bar::-webkit-progress-value {
      background-color: #fe8d59;
      border-radius: 4px;
    }

    .progress-bar::-moz-progress-bar {
      background-color: #fe8d59;
      border-radius: 4px;
    }

    .category-group {
      margin-bottom: 20px;
    }

    .category-group-2 {
      margin-bottom: 20px;
    }

    .cat_stats {
      display: none;
    }

    #show-more-btn {
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 11px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
    }

    #show-more-btn-2 {
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 11px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
    }

    #show-more-table-btn {
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 13px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
      margin-bottom: 20px;
    }

    #complete-btn {
      display: flex;
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 13px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
      margin-bottom: 20px;
    }

    #resumed-btn {
      display: none;
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 13px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
      margin-bottom: 20px;
    }

    #show-more-btn:hover {
      background-color: #ff7043;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-family: Arial, sans-serif;
    }

    th,
    td {
      padding: 10px;
      text-align: center;
      border: 2px solid #666;
      font-weight: 600;
      /* Make text slightly bolder */
    }

    th {
      background-color: #2e3141;
      color: #ee5f0f;
      border-bottom: 3px solid #ee5f0f;
    }


    td.boolean-cell {
      font-size: 1.5em;
    }

    td.accuracy,
    td.loss,
    td.val_accuracy,
    td.val_loss {
      width: 70px;
      color: #fff;
      /* Ensure text contrast on colored background */
    }

    .green-check {
      color: #66bb6a;
    }

    .red-cross {
      color: #ff7043;
    }

    .separator {
      border: none;
      width: 1px;
    }

    td.separator {
      background-color: #2e3141;
      /* Set a consistent color for the separator column */
      border: none;
      /* Remove the border for the separator column */
    }

    tr:nth-child(odd) {
      background-color: #3a3b44;
      /* Softer color for odd rows */
    }

    tr:nth-child(even) {
      background-color: #404351;
      /* Slightly darker, but still subtle */
    }

    th,
    td {
      padding: 5px;
      /* Reduce padding to make rows less tall */
      text-align: center;
      border: 2px solid #666;
      font-weight: 600;
      /* Keep the bold text */
    }

    td.accuracy,
    td.loss,
    td.val_accuracy,
    td.val_loss {
      padding: 8px;
      /* Slightly larger padding for the score cells for readability */
    }

    tbody tr {
      height: 40px;
      /* Adjust this value to your preferred fixed row height */
    }

    td {
      vertical-align: middle;
      overflow: hidden;
      /* Prevent overflow from expanding the row */
      white-space: nowrap;
      /* Prevent text wrapping inside the cells */
      text-overflow: ellipsis;
      /* Add ellipsis if the text is too long */
    }

    table td {
      padding: 0em 0.35em;
    }

    table th {
      padding: 5px;
    }

    .a-custom {
      color: #ee5f0f;
      text-decoration: underline;
      cursor: pointer;
    }


    .tooltip-container {
      position: absolute;
      display: inline-block;
      cursor: pointer;
      right: 8px;
      top: 4px;
    }

    .tooltip-container .tooltiptext {
      visibility: hidden;
      width: 150px;
      background-color: #555;
      color: #fff;
      text-align: center;
      border-radius: 5px;
      padding: 5px;
      position: absolute;
      z-index: 1;
      bottom: 125%;
      /* Position above the icon */
      left: 50%;
      margin-left: -75px;
      opacity: 0;
      transition: opacity 0.3s;
      width: 200px;
    }

    .tooltip-container .tooltiptext::after {
      content: "";
      position: absolute;
      top: 100%;
      /* Arrow below the tooltip */
      left: 50%;
      margin-left: -5px;
      border-width: 5px;
      border-style: solid;
      border-color: #555 transparent transparent transparent;
    }

    .tooltip-container:hover .tooltiptext {
      visibility: visible;
      opacity: 1;
    }

    .info-icon {
      margin-left: 5px;
      color: #ee5f0f;
      font-weight: bold;
    }
  </style>
</head>

<body class="is-preload" style="
      background-image: linear-gradient(
          to top,
          rgba(46, 49, 65, 0.8),
          rgba(46, 49, 65, 0.8)
        ),
        url(images/ABO/cosas.webp);
    ">

  <!-- Disclaimer: El objetivo de este blog es demostrar mis habilidades en machine learning, porque mis habilidades como web developer no me enorgullecen ü§¶‚Äç‚ôÇÔ∏è -->

  <!-- Advertencia: Este c√≥digo puede generar secuelas como falta de apetito, dolor de ojos, depresi√≥n y p√©rdida de cabello. Contin√∫a leyendolo bajo tu propio riesgo -->

  <!-- Page Wrapper -->
  <div id="page-wrapper">
    <!-- Header -->
    <header id="header">
      <a href="index.html">
        <h1>Nicol√°s Pav√≥n</h1>
      </a>
      <nav>
        <a href="ABO-eng.html">ENG</a>
        <a href="#menu">Men√∫</a>
      </nav>
    </header>

    <!-- Menu -->
    <nav id="menu"></nav>

    <!-- Wrapper -->
    <section id="wrapper">
      <header id="ABO-header">
        <div class="inner">
          <h2>Clasificando imagenes de Amazon</h2>
        </div>
      </header>

      <!-- Content -->
      <div class="wrapper">
        <div class="inner">
          <section>
            <h3 class="orange_title major">Introducci√≥n</h3>
            <p>Esto es la continuaci√≥n del proyecto sobre redes neuronales y clasificacion de im√°genes de la
              materia "Inteligencia Artificial 2" dictada por Juan Kurucz y Ernesto Ocampo en la Universidad Cat√≥lica
              del
              Uruguay. Trata de la preparaci√≥n de un dataset problem√°tico y realista de productos de
              e-commerce, para luego entrenar una red neuronal utilizando transfer learning, entre otras t√©cnicas
              interesantes.</p>
            <p>En este blog explico en detalle los problemas y soluciones encontrados en el camino, por lo que su
              version completa puede ser muy extensa (15 min de lectura). Si cuentas con poco tiempo puedes cambiar a la
              version resumida (8 min)
              haciendo click en el siguiente bot√≥n:
            </p>

            <button id="complete-btn" onclick="toggleVersion()" style="margin-top: -20px; margin-bottom: 60px">Ver
              version resumida</button>
            <button id="resumed-btn" onclick="toggleVersion()" style="margin-top: -20px; margin-bottom: 60px">Ver
              version original (recomendado)</button>
          </section>
          <section class="extended">
            <h3 class="orange_title major">El problema</h3>
            <p>
              En los √∫ltimos 20 a√±os, el comercio electr√≥nico ha crecido exponencialmente. Basta con observar el poder y
              el tama√±o de sitios como Amazon, Alibaba o incluso Mercado Libre para darse cuenta de la importancia que
              tienen hoy en d√≠a. A partir de esto, podemos concluir que, si hay algo que tienen estos gigantes de la
              inform√°tica, es una enorme cantidad de datos, entre ellos, muchas im√°genes. Pese a esto, los datos no
              sirven de nada si no se pueden interpretar y trabajar, por lo que es √∫til poder clasificarlos para darles
              un uso adecuado y sacarles todo el provecho posible.
            </p>
            <p>Sin embargo, mi objetivo no es resolver ese gran desaf√≠o global. Siendo realistas,
              estoy m√°s interesado en mostrar mis habilidades en machine learning üòé. As√≠ que aqu√≠ va!
            </p>

            <h3 class="orange_title major">Los datos</h3>
            <p>
              Entre todos los conjuntos de datos disponibles, nos topamos con uno <i>interesante</i>, el <a
                class="a-custom" href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">Amazon Berkeley
                Objects (ABO)
                Dataset.</a> Este conjunto de datos nos proporciona im√°genes de aproximadamente 147,000 productos de
              Amazon, con su correspondiente metadata, que incluye su categor√≠a, color, palabras clave, marca, nombre,
              modelo, entre otros. Adem√°s, ofrece renders en 3D y algunos otros detalles interesantes. Si bien a√∫n no
              hemos explorado los datos en profundidad para determinar su pureza, apreciamos el hecho de que provienen
              de Amazon, lo que hace que las im√°genes sean ideales para este problema.
            </p>

            <h3 class="orange_title major">La tecnolog√≠a</h3>
            <p>
              Si bien hoy en d√≠a suelen utilizarse los transformers para este tipo de problemas, en este caso
              utilizaremos redes convolucionales, partiendo de un modelo preentrenado como Inception-v3 y aplicando
              transfer learning, donde eliminaremos las capas superiores de clasificaci√≥n y a√±adiremos nuevas capas
              especializadas para esta tarea. Por √∫ltimo, aplicaremos fine-tuning para mejorar el rendimiento. El c√≥digo
              fue desarrollado <a class="a-custom" target="_blank"
                href="https://colab.research.google.com/drive/1uU5ySJ_FRQYYXtaBswYEyEkJcovputsj?usp=sharing">en Google
                Colab.</a>
            </p>

            <h3 class="orange_title major">El objetivo</h3>
            <p>
              Nuestro objetivo es clasificar el producto en la imagen, asumiendo que la imagen corresponde a un producto
              de comercio electr√≥nico. Tomando esto en cuenta y analizando el conjunto de datos, observamos la propiedad
              <i class="variable">product_type</i>, la cual tiene alrededor de 574 clases que var√≠an en nivel de
              precisi√≥n, desde "RING" hasta "BISS" (Business, Industrial, and Scientific Supplies). Partiremos de esta
              propiedad del conjunto de datos para entrenar nuestro modelo.
            </p>
          </section>
          <section class="resumed">
            <h3 class="orange_title major">Resumen</h3>
            <p>
              El comercio electr√≥nico ha crecido enormemente en las √∫ltimas d√©cadas, impulsado por gigantes como Amazon
              y Alibaba. Con este crecimiento, la cantidad de datos tambi√©n ha aumentado, especialmente en forma de
              im√°genes de productos. Para aprovechar estos datos, es fundamental poder clasificarlos adecuadamente.
              Aunque, siendo realistas, en este caso no estoy aqu√≠ para salvar el comercio global, sino para mostrar lo
              que s√© hacer en machine learning üòÖ. Vamos a trabajar con el <a class="a-custom"
                href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">Amazon Berkeley
                Objects (ABO)
                Dataset.</a>, que contiene
              im√°genes y metadata de m√°s de 147,000 productos de Amazon.
            </p>
            <p>
              Para abordar este problema de clasificaci√≥n, usaremos redes convolucionales y transfer learning con un
              modelo preentrenado como Inception-v3. Eliminaremos las capas de clasificaci√≥n originales y las
              reemplazaremos con capas personalizadas para mejorar el rendimiento en la tarea espec√≠fica de
              clasificaci√≥n de productos, ajustando el modelo con fine-tuning. El objetivo es clasificar la mayor
              cantidad de clases diferentes de productos bas√°ndonos en la propiedad product_type del conjunto de datos,
              que incluye desde
              categor√≠as muy espec√≠ficas como "RING" hasta otras m√°s amplias como "BISS" (Business, Industrial, and
              Scientific Supplies).
            </p>
          </section>
        </div>
      </div>
      <div class="wrapper alt style4">
        <div class="inner">
          <section>
            <h2 class="white-big major">Informacion y estructura del dataset</h2>
            <h3 class="orange_title major">Estructura del dataset</h3>
            <p>
              <a class="a-custom" href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">El conjunto de
                datos</a> cuenta con
              varios archivos para descargar, de los cuales nos interesan <i class="variable">listings.tar</i> (listado
              de productos y metadata) e <i class="variable">images-small.tar</i> (cat√°logo de im√°genes reescaladas a un
              m√°ximo de 256 p√≠xeles).
            </p>
            <p class="extended">El archivo <i class="variable">listings.tar</i> contiene 15 archivos
              .json, cada uno con una lista de objetos, siendo cada objeto un producto de Amazon. Utilizaremos un script
              para pasar la informaci√≥n relevante de estos objetos a archivos .csv, para que sean m√°s c√≥modos de
              trabajar. Los objetos tienen una serie de atributos, de los cuales nos interesar√°n <b><i>item_id</i></b>,
              <b><i>product_type</i></b>, <b><i>main_image_id</i></b> y <b><i>other_image_id</i></b>
            </p>
            <h3 class="orange_title major">Atributos del dataset y estadisticas</h3>
            <p>
              Una vez que tenemos el archivo .csv inicial, procedemos a observar la distribuci√≥n de las clases:
            </p>

            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS inicial desb.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset inicial</i></p>
              </span>
            </div>

            <p class="extended">Como se ve en la imagen, el conjunto de datos est√° totalmente desbalanceado, con muchos
              ejemplos para
              ciertas categor√≠as y casi ninguno en otras. Al observar los datos en detalle, vemos que hay 574
              categor√≠as, de las cuales 460 tienen menos de 100 ejemplos. Esto es un problema, ya que necesitamos una
              buena cantidad de im√°genes por categor√≠a para poder identificar ese tipo de objetos con √©xito, y solo 100
              o menos no son suficientes.</p>
            <p class="extended">
              Para lidiar con este problema, en un principio trabajaremos solo con las
              categor√≠as que tengan m√°s ejemplos, balanceando los mismos para evitar sesgos entre las categor√≠as al
              momento de entrenar. Originalmente, se opt√≥ por trabajar con 170 categor√≠as con al menos 50 ejemplos por
              categor√≠a. Esto no dio resultado, por lo que se redujo el conjunto de datos a todas las categor√≠as que
              tuvieran al menos 150 ejemplos, con un tope de 400. Esta fue una decisi√≥n algo arbitraria, por lo que, si
              se vuelve necesario, es posible encontrar una mejor selecci√≥n de categor√≠as y ejemplos.
            </p>

            <p class="resumed">
              El dataset est√° desbalanceado, con 574 categor√≠as, de las cuales 460 tienen menos de 100 ejemplos, lo que
              dificultar√° identificar objetos correctamente. Para abordar esto, se seleccionar√°n categor√≠as con al menos
              150 ejemplos y un m√°ximo de 400. Esta selecci√≥n fue algo arbitraria y podr√≠a mejorarse si fuera necesario.
            </p>
            <p style="margin-bottom: 10px;">Una vez realizados los filtros, podemos observar las estad√≠sticas del
              conjunto de datos final:
            </p>

            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS min 150 max 400.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset simplificado</i></p>
              </span>
            </div>

            <p>En este conjunto de datos tenemos 80 categor√≠as, mucho mejor balanceadas que las 574 del conjunto de
              datos inicial. Esto facilitar√° el trabajo, ya que la red neuronal final ser√° m√°s f√°cil de entrenar y
              tendr√° un promedio de ejemplos por categor√≠a considerablemente mayor.
            </p>

            <h3 class="orange_title major" id="inspeccion">Inspecci√≥n del dataset</h3>
            <p>
              En este paso, analizaremos el conjunto de datos previamente refinado en busca de posibles problemas
              evidentes, entre los cuales encontramos:
            <h5>Categorias confundibles: </h5>
            <p>Estas categor√≠as contienen objetos muy similares entre s√≠. Incluso, en algunos casos, la √∫nica forma de
              diferenciarlos es leyendo el texto que tiene el producto en la etiqueta. Esto es un problema, ya que para
              la red neuronal ser√°
              dif√≠cil aprender las diferencias.</p>
            <ul>
              <li><i class="variable">ACCESORY</i> &#8596; <i class="variable">HAT</i></li>
              <li><i class="variable">STORAGE_HOOK</i> &#8596; <i class="variable">TOOLS</i></li>
              <li><i class="variable">NUTRITIONAL_SUPLEMENT</i> &#8596; <i class="variable">VITAMINS</i> &#8596; <i
                  class="variable">HEALTH_PERSONAL_CARE</i></li>
              <li><i class="variable">LUGGAGE</i> &#8596; <i class="variable">SUIT_CASE</i></li>
              <li><i class="variable">FINERING</i> &#8596; <i class="variable">RING</i></li>
              <li><i class="variable">FINENECKLACEBRACALETANKLET</i> &#8596; <i class="variable">NECKLACE</i></li>
              <li><i class="variable">FINEEARING</i> &#8596; <i class="variable">EARRING</i></li>
            </ul>
            <p class="extended">Exceptuando los casos de 'fine x' ‚Üî 'x', en un principio conservaremos estas categor√≠as
              y observaremos si
              son efectivamente problem√°ticas al momento de clasificar. Para los casos 'fine x', nos quedaremos con los
              que no son "fine", ya que son m√°s abarcativos y siguen preservando la forma general.</p>

            <h5>Categorias genericas: </h5>
            <p class="extended">Estas categor√≠as contienen objetos muy variados, por lo que ser√° m√°s dif√≠cil entrenar a
              la red en busca
              de patrones compartidos. Si todos los objetos de una categor√≠a var√≠an en forma, no existe un conjunto de
              features o patrones que los unifique, y la red no podr√° categorizar eficientemente. Solo ser√≠a posible
              lograrlo si cada subgrupo de objetos en esta categor√≠a tuviera suficientes im√°genes, pero como quiz√°s de
              400 im√°genes solo 90 pertenecen a uno de estos objetos, ser√° muy dif√≠cil de entrenar. Por esta raz√≥n,
              estas categor√≠as ser√°n eliminadas del conjunto de datos.
            </p>
            <p class="resumed">Estas categor√≠as son demasiado variadas, lo que dificulta que la red encuentre patrones
              comunes. Al no
              haber suficientes im√°genes por subgrupo dentro de cada categor√≠a, la red no podr√° clasificarlas
              eficientemente, por lo que ser√°n eliminadas del dataset.</p>
            <div class="generic-cat">
              <ul>
                <li><i class="variable">HOME</i></li>
                <li><i class="variable">WIRELESS_ACCESORY</i></li>
                <li><i class="variable">ACCESORY_OR_PART_OR_SUPPLY</i></li>
                <li><i class="variable">BABY_PRODUCT</i></li>
                <li><i class="variable">COMPUTER_ADDON</i></li>
                <li><i class="variable">GROCERY</i></li>
                <li><i class="variable">SPORTING_GOODS</i></li>
                <li><i class="variable">PANTRY</i></li>
                <li><i class="variable">KITCHEN</i></li>
                <li><i class="variable">JANITORY_SUPPLY</i></li>
                <li><i class="variable">HOMEFURNITURE_AND_DECOR</i></li>
                <li><i class="variable">HARDWARE</i></li>
              </ul>

              <div class="gtr-uniform home-images"
                style="flex-direction: column; align-items: flex-start; margin-bottom: 20px; margin-left: 16px; flex: 1; min-width: 0;">
                <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Ejemplos de productos en la categoria
                  <i class="variable">HOME</i>
                </h5>
                <div style="flex-direction: row; display: flex;">
                  <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                    <div class="oth-row">
                      <span>
                        <img src="images/ABO/HOME_3.jpg" alt="Home product example 2" />
                      </span>
                      <span>
                        <img src="images/ABO/HOME_2.jpg" alt="Home product example 1" />
                      </span>
                      <span>
                        <img src="images/ABO/HOME_1.jpg" alt="Home product example 1" />
                      </span>
                    </div>
                    <p style="margin: 0px;"><i>(No se parecen en nada)</i></p>
                  </div>
                </div>
              </div>
            </div>

            </p>
            <h3 class="orange_title major">Balanceo del dataset</h3>
            <p class="extended">
              Como se coment√≥ previamente, un posible problema es el sesgo que puede generar el desbalance de ejemplos
              al momento de entrenar una red neuronal. Si en nuestra red tenemos mil ejemplos de zapatos y cien ejemplos
              de sillones, para la red las probabilidades de recibir un zapato son 10 veces mayores que las de recibir
              un sill√≥n. En este caso, la red podr√≠a retornar siempre "zapato", acertando la mayor√≠a de las veces. Esto
              afectar√≠a la clasificaci√≥n de forma bastante dr√°stica, por lo que nos interesa tener el conjunto de datos
              lo m√°s balanceado posible.

              En nuestro caso, tenemos varias categor√≠as con menos de 400 ejemplos, que es el n√∫mero ideal que queremos
              mantener en todas las categor√≠as. Para lograr el balance deseado, tomaremos en cuenta las "other_images"
              disponibles por cada objeto que nos provee el dataset. Estas im√°genes pueden ayudarnos a completar la
              cantidad de im√°genes para aquellas categor√≠as que lo necesiten.
            </p>
            <p class="resumed">
              El desbalance de ejemplos puede generar sesgos en la red neuronal, favoreciendo categor√≠as con m√°s
              ejemplos. Para evitar esto, es importante balancear el dataset. Como algunas categor√≠as tienen menos de
              400 ejemplos, utilizaremos las "other_images" disponibles para completar las im√°genes necesarias.
            </p>
            <h5>Ejemplos satisfactorios</h5>
            <p>Luego de una no muy breve inspecci√≥n, observamos casos satisfactorios en los que las "other_images" son
              suficientemente similares (pero no id√©nticas) al producto original.</p>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">SOFA</i></h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <img src="images/ABO/SOFA_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/SOFA_OTH_3.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/SOFA_OTH_1.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/SOFA_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <h5>Ejemplos problematicos</h5>
            <p>Sin embargo, tambi√©n observamos im√°genes que no son del producto en s√≠, sino de una tabla descriptiva, un
              color, o de una toma general en la que el objeto es casi indistinguible.</p>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">LEGUME</i></h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image" style="max-width: 170px;">
                  <span>
                    <img src="images/ABO/LEGUME_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/LEGUME_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_4.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>

            <div class="gtr-uniform home-images extended"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">RUG</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <img src="images/ABO/RUG_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/RUG_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/RUG_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/RUG_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <p class="extended">Estos casos nos perjudican. Nos interesa tener cierta variabilidad en las im√°genes para
              que nuestra red
              se vuelva m√°s robusta, pero cuando tenemos im√°genes demasiado complejas, o que ni siquiera contienen el
              objeto en s√≠, perjudican el entrenamiento de la red, ya que esta asociar√° patrones err√≥neos a la categor√≠a
              en cuesti√≥n. ¬°Recuerda el ejemplo de <i class="variable">RUG</i>! Ser√° un problema en el futuro.
            </p>
            <p class="extended">Para superar este problema, haremos un filtrado de las "other_images" utilizando redes
              neuronales
              preentrenadas. En este caso, utilizaremos el modelo VGG16, quitando las capas de clasificaci√≥n. Esto nos
              dejar√° una red que solo detecta features en una imagen, pero no la clasifica.

              Con esta red, procederemos a extraer las features de la imagen principal de cada objeto (main_image) y
              luego compararemos dichas features con las de cada una de las "other_images" de este objeto, obteniendo un
              coeficiente de similitud entre ellas. Este coeficiente nos indicar√° qu√© tan similares son las
              "other_images" a la imagen principal, asignando un valor muy bajo a aquellas que no sean similares.
            </p>

            <p class="resumed">
              Estos casos complican el entrenamiento, ya que im√°genes demasiado complejas o irrelevantes hacen que la
              red aprenda patrones incorrectos. Para resolverlo, usaremos el modelo VGG16, eliminando las capas de
              clasificaci√≥n, para extraer y comparar las features entre la imagen principal y las "other_images". As√≠,
              obtendremos un coeficiente de similitud que utilizaremos para filtrar las im√°genes menos √∫tiles.
            </p>
            <p style="margin-bottom: 10px;">Aqui observamos algunos ejemplos del uso de esta t√©cnica:</p>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">SOFA</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>

                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/SOFA_MAIN.jpg" alt="" />
                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
              display: flex;
              flex-direction: column;
              height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                    
                      margin: 0px;
                      margin-bottom: -9px;
                      font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.861</i></p>
                      <progress value="0.8615963" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.640</i></p>
                      <progress value="0.6404396" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.599</i></p>
                      <progress value="0.5996146" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.196</i></p>
                      <progress value="0.1969997" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_4.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">OTTOMAN</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>

                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/OTTOMAN-MAIN.jpg" alt="" />
                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
              display: flex;
              flex-direction: column;
              height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                    
                      margin: 0px;
                      margin-bottom: -9px;
                      font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.819</i></p>
                      <progress value="0.819" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.8198348.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.689</i></p>
                      <progress value="0.689" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.6890952.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.581</i></p>
                      <progress value="0.581" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.5811923.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.192</i></p>
                      <progress value="0.19274572" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.19274572.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>

            <p class="extended" style="margin-bottom: 10px;">¬°Genial! Vemos que funciona, sin embargo, encontramos
              algunos problemas::
            </p>
            <p class="extended">La categor√≠a RUG nos complica un poco. Si observamos algunos ejemplos, veremos que la
              "main_image" suele
              contener la alfombra en una escena gen√©rica, un poco "escondida". Esto causa que el coeficiente de
              similitud de las "other_images" sea muy bajo, dejando fuera muchas im√°genes √∫tiles.</p>
            <div class="gtr-uniform home-images extended"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">RUG</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/RUG-MAIN-SIM.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.273</i></p>
                      <progress value="0.27311817" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.27311817.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.213</i></p>
                      <progress value="0.21372926" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.21372926.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.187</i></p>
                      <progress value="0.18717194" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.18717194.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <p class="extended">Utilizaremos un threshold de 0.5 como criterio para seleccionar las "other_images",
              eligiendo aquellas
              que tengan un coeficiente de similitud mayor a este para completar las im√°genes faltantes en una
              categor√≠a. Sin embargo, en el caso de la categor√≠a <i class="variable">RUG</i>, tomaremos un threshold de
              solo 0.2, ya que, debido a las caracter√≠sticas de las "main_images", la mayor√≠a de las "other_images"
              quedar√≠an fuera.
            </p>
            <p class="resumed">¬°Genial! Vemos que funciona, utilizaremos un threshold de 0.5 como criterio para
              seleccionar las "other_images", eligiendo aquellas
              que tengan un coeficiente de similitud mayor a este para completar las im√°genes faltantes en una
              categor√≠a.
            </p>

            <h3 class="orange_title major">Dataset final</h3>
            <p class="resumed">
              Para finalizar, organizamos las im√°genes por categor√≠a usando los similarity scores de las "other_images"
              para completar aquellas con pocos ejemplos. El dataset resultante tiene 65 categor√≠as y unas 25,800
              im√°genes. Aunque algunas categor√≠as no alcanzaron las 400 im√°genes, al tener m√°s de 320, se consideraron
              suficientes.
            </p>
            <p class="extended">
              Por √∫ltimo, para terminar de armar el conjunto de datos y poder entrenar la red neuronal, debemos
              organizar las im√°genes, agrup√°ndolas por categor√≠a. Una vez que conocemos los similarity scores de las
              "other_images", procedemos a mover todas las "main_images" a la carpeta de su categor√≠a y completamos
              aquellas que tengan pocos ejemplos con las "other_images" que tengan mayor similarity score.
            </p>
            <p style="margin-bottom: 10px;">
              Este es el balance del dataset resultante, mucho mejor!
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS FINAL.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset final</i></p>
              </span>
            </div>
            <p id="categorias" class="extended">
              Este dataset cuenta con 65 categor√≠as y aproximadamente 25,800 im√°genes. Reconocemos que hay categor√≠as
              que no alcanzaron las 400 im√°genes debido a la falta de un buen similarity score, pero dado que a√∫n tienen
              una cantidad considerable (>320), simplemente lo ignoraremos.
            </p>
            <h5 style="margin-bottom: 10px;" class="extended">
              Categorias finales:
            </h5>
            <div class="categories-container extended"
              style="display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 40px;">
              <!-- Categor√≠as comunes diarias -->
              <div class="category-group" style="width: 100%;">
                <i class="variable_2">COFFEE</i>
                <i class="variable_2">TEA</i>
                <i class="variable_2">BREAD</i>
                <i class="variable_2">DRINKING_CUP</i>
                <i class="variable_2">HEADPHONES</i>
                <i class="variable_2">CHARGING_ADAPTER</i>
                <i class="variable_2">SHOES</i>
                <i class="variable_2">PILLOW</i>
                <i class="variable_2">CHAIR</i>
                <i class="variable_2">WALL_ART</i>
                <i class="variable_2">LAMP</i>
                <i class="variable_2">RING</i>
                <i class="variable_2">HAT</i>
                <i class="variable_2">BACKPACK</i>
                <i class="variable_2">SUITCASE</i>
                <i class="variable_2">PLANTER</i>
                <i class="variable_2">WALLET</i>
              </div>

              <button id="show-more-btn" onclick="showMoreCategories()" style="margin-top: -20px;">...ver m√°s</button>

              <!-- Comida y Salud -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Comida y Salud</h5>
                <i class="variable_2">LEGUME</i>
                <i class="variable_2">HERB</i>
                <i class="variable_2">HEALTH_PERSONAL_CARE</i>
                <i class="variable_2">SKIN_CLEANING_AGENT</i>
                <i class="variable_2">SKIN_MOISTURIZER</i>
                <i class="variable_2">BEAUTY</i>
                <i class="variable_2">VITAMIN</i>
                <i class="variable_2">NUTRITIONAL_SUPPLEMENT</i>
              </div>

              <!-- Muebles -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Muebles</h5>
                <i class="variable_2">SHELF</i>
                <i class="variable_2">CABINET</i>
                <i class="variable_2">DESK</i>
                <i class="variable_2">TABLE</i>
                <i class="variable_2">HEADBOARD</i>
                <i class="variable_2">BED</i>
                <i class="variable_2">OTTOMAN</i>
                <i class="variable_2">STOOL_SEATING</i>
                <i class="variable_2">SOFA</i>
              </div>

              <!-- Decoraci√≥n y Ropa de Cama -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Decoraci√≥n y Ropa de Cama</h5>
                <i class="variable_2">RUG</i>
                <i class="variable_2">FLAT_SHEET</i>
                <i class="variable_2">FURNITURE_COVER</i>
                <i class="variable_2">LIGHT_FIXTURE</i>
              </div>

              <!-- Accesorios y Joyas -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Accesorios y Joyas</h5>
                <i class="variable_2">NECKLACE</i>
                <i class="variable_2">EARRING</i>
                <i class="variable_2">ACCESSORY</i>
                <i class="variable_2">HANDBAG</i>
                <i class="variable_2">BOOT</i>
                <i class="variable_2">SANDAL</i>
                <i class="variable_2">PORTABLE_ELECTRONIC_DEVICE_COVER</i>
                <i class="variable_2">CELLULAR_PHONE_CASE</i>
                <i class="variable_2">SCREEN_PROTECTOR</i>
              </div>

              <!-- Art√≠culos de Oficina y Limpieza -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Art√≠culos de Oficina y Limpieza</h5>
                <i class="variable_2">OFFICE_PRODUCTS</i>
                <i class="variable_2">STORAGE_BINDER</i>
                <i class="variable_2">STORAGE_HOOK</i>
                <i class="variable_2">CLEANING_AGENT</i>
                <i class="variable_2">BATTERY</i>
              </div>

              <!-- Otros -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Otros</h5>
                <i class="variable_2">AUTO_ACCESSORY</i>
                <i class="variable_2">TOOLS</i>
                <i class="variable_2">SAFETY_SUPPLY</i>
                <i class="variable_2">FOOD_SERVICE_SUPPLY</i>
                <i class="variable_2">BISS</i>
                <i class="variable_2">LIGHT_BULB</i>
                <i class="variable_2">OUTDOOR_LIVING</i>
                <i class="variable_2">PET_SUPPLIES</i>
              </div>
            </div>
          </section>
        </div>
      </div>

      <div class="wrapper style3">
        <div class="inner">
          <section>
            <h2 class="white-big major">Dise√±o y entrenamiento de la red neuronal</h2>
            <h3 class="orange_title major">Entrenamiento de la red</h3>
            <div class="extended">
              <p>Lograr que la red tuviera un buen rendimiento fue dif√≠cil. Como se mencion√≥ previamente, se opt√≥ por
                aplicar transfer learning, partiendo de un modelo preentrenado sin sus top layers (las capas de
                clasificaci√≥n). Este modelo se encargar√≠a de detectar las features o caracter√≠sticas principales en las
                im√°genes, y luego sobre esto
                se agregar√≠an capas personalizadas encargadas de clasificar estas features dentro de las 65 categor√≠as
                posibles. Por √∫ltimo, se aplicar√≠a fine-tuning para optimizar el rendimiento.
              </p>
              <p>En un principio, se opt√≥ por utilizar el modelo VGG-16, agregando varias capas para la clasificaci√≥n (3
                capas dense y 1 capa de dropout). Este modelo tuvo un rendimiento muy pobre.</p>
              <p>Se opt√≥ por simplificar el problema reduciendo la cantidad de categor√≠as y, adem√°s, utilizar
                Inception-v3. Aqu√≠ se empezaron a notar mejoras, sobre todo cuando se simplific√≥ la etapa de
                clasificaci√≥n, reduci√©ndola a 2 dense layers, 1 dropout y 1 BatchNormalization.</p>
              <p>Luego de varias iteraciones, se lograron m√©tricas satisfactorias. El modelo m√°s performante solo agrega
                una capa dense de 256 unidades, acompa√±ada de un Dropout(0.4) y una capa de data augmentation con varias
                t√©cnicas para evitar el overfitting. Sorprendentemente, esta red tan sencilla es de las m√°s
                performantes.
                Por esto, podemos asumir que el modelo Inception-v3 ya hace un excelente trabajo al detectar las
                features
                en una imagen, dej√°ndonos poco trabajo para completar el modelo.</p>
              <p>Una vez que encontramos un dise√±o de red eficiente, continuamos con las pruebas, estudiando qu√©
                beneficia
                al modelo y qu√© lo perjudica. En la siguiente tabla se pueden observar las m√©tricas de los distintos
                dise√±os experimentados: </p>
            </div>
            <div class="resumed">
              <p>Lograr un buen rendimiento fue complicado. Se utiliz√≥ transfer learning, empezando con un modelo
                preentrenado sin sus capas de clasificaci√≥n, al que se le a√±adieron capas personalizadas para clasificar
                las 65 categor√≠as. Inicialmente, se prob√≥ con VGG-16 y varias capas dense, pero el rendimiento fue
                pobre.
              </p>
              <p> Al simplificar el problema reduciendo categor√≠as y utilizando Inception-v3 con una arquitectura m√°s
                simple (2 dense layers, dropout y BatchNormalization), se notaron mejoras significativas. Finalmente, el
                modelo m√°s eficiente solo a√±adi√≥ una capa dense de 256 unidades, dropout, y data augmentation,
                demostrando que Inception-v3 ya detecta muy bien las features, dejando poco trabajo adicional.
              </p>
              <p> A continuaci√≥n, se muestran las m√©tricas de los diferentes dise√±os experimentados:</p>
            </div>
            <div class="gtr-uniform home-images"
              style="margin-bottom: 10px; flex-direction: column; align-items: flex-start; background-color: #313345">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Tabla comparativa de los modelos</h5>
              <table id="score-table" style="margin: 0px">
                <thead>
                  <tr>
                    <th>Version</th>
                    <th style="position: relative">Dense Layers <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Capas completamente conectadas, donde cada neurona est√° conectada a
                          todas las neuronas de la capa anterior.</span>
                      </span></th>
                    <th style="position: relative">Data <br>Augmentation <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">T√©cnica para aumentar el tama√±o del conjunto de datos mediante
                          transformaciones como rotaciones, recortes, o espejado de im√°genes.</span>
                      </span></th>
                    <th style="position: relative; padding-right: 29px;">BatchNorm <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Normalizaci√≥n por lotes que acelera el entrenamiento y mejora la
                          estabilidad de la red.</span>
                      </span></th>
                    <th style="position: relative; padding-right: 29px;">Dropout <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">T√©cnica para prevenir sobreajuste eliminando aleatoriamente neuronas
                          durante el entrenamiento.</span>
                      </span></th>
                    <th class="separator"></th>
                    <th style="position: relative; padding-right: 29px;">Accuracy <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Precisi√≥n del modelo, que indica la proporci√≥n de predicciones
                          correctas.</span>
                      </span></th>
                    <th style="position: relative">Loss <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Mide qu√© tan diferentes son las predicciones del modelo en comparaci√≥n
                          con los valores reales.</span>
                      </span></th>
                    <th style="position: relative">Val Accuracy <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Precisi√≥n del modelo en el conjunto de validaci√≥n, que indica el
                          rendimiento fuera del conjunto de entrenamiento.</span>
                      </span></th>
                    <th style="position: relative">Val Loss <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Mide qu√© tan diferentes son las predicciones del modelo en el conjunto
                          de validaci√≥n para detectar sobreajuste.</span>
                      </span></th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="description">v1.1</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.89</td>
                    <td class="loss">0.35</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.48</td>
                  </tr>
                  <tr>
                    <td class="description">v1.2</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚ùå</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.97</td>
                    <td class="loss">0.09</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.56</td>
                  </tr>
                  <tr>
                    <td class="description">v1.3</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚ùå</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.91</td>
                    <td class="loss">0.26</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.46</td>
                  </tr>
                  <tr>
                    <td class="description">v1.4</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚ùå</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.95</td>
                    <td class="loss">0.15</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.51</td>
                  </tr>
                  <tr>
                    <td class="description">v2.1</td>
                    <td>1x(256) 1x(512)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.83</td>
                    <td class="loss">0.57</td>
                    <td class="val_accuracy">0.84</td>
                    <td class="val_loss">0.54</td>
                  </tr>
                  <tr>
                    <td class="description">v2.2</td>
                    <td>1x(512) 1x(1024)</td>
                    <td class="boolean-cell">‚úÖ</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="boolean-cell">‚úÖx2</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.85</td>
                    <td class="loss">0.47</td>
                    <td class="val_accuracy">0.84</td>
                    <td class="val_loss">0.55</td>
                  </tr>
                  <!-- Add more rows as needed -->
                </tbody>
              </table>
              <p style="margin-bottom: 0px; margin-top: 0px;"><i style="font-size: 14px">Todos los modelos utilizan
                  inception-v3 y fueron
                  entrenados con 20 epochs en el
                  entrenamiento inicial y 15 en la etapa de
                  fine-tunning</i></p>
              </span>
            </div>
            <div class="extended">
              <p> Analizando un poco estas estad√≠sticas, podemos observar en los modelos v1.2 y v1.4 mejoras
                sustanciales en
                los valores de accuracy y loss, pero a la vez notamos valores de val_loss un poco peores, esto nos
                indica overfitting, lo cual tiene sentido. La capa de data augmentation busca hacer que nuestro modelo
                sea
                m√°s robusto, alterando las im√°genes de varias formas, como rotaciones aleatorias, cambios en el
                contraste
                o brillo, zooms aleatorios, etc. A su vez, el objetivo principal de las capas dropout es prevenir el
                overfitting, por lo que es entendible que empeore su performance.</p>

              <p>Por otra parte, observamos que el modelo v1.3, que carece de la capa BatchNormalization, tiene una
                mejora
                interesante en la performance. Si bien este tipo de capas son muy importantes y frecuentemente
                utilizadas
                en modelos de clasificaci√≥n de im√°genes, podemos atribuir esta baja en la performance al hecho de que se
                est√° utilizando en la etapa final de clasificaci√≥n del modelo. Quiz√°s ser√≠a m√°s √∫til en una etapa
                intermedia de un modelo m√°s complejo. </p>

              <p>Otro hecho interesante que podemos observar de las estad√≠sticas es la similitud de performances entre
                modelos respecto al val_accuracy. Como podemos ver, todos los modelos tienen valores muy similares. Mi
                teor√≠a es que esto se debe a que varias im√°genes utilizadas para la validaci√≥n est√°n simplemente mal
                etiquetadas. Son casos similares a los de la categor√≠a RUG, donde la primera imagen, adem√°s de contener
                la
                alfombra, tambi√©n suele contener otros objetos como sillones, sillas, cuadros, etc.

                Teniendo esto en cuenta, podemos suponer que el modelo nunca ser√° capaz de superar cierta performance,
                porque algunas im√°genes est√°n clasificadas bajo cierta categor√≠a, pero contienen objetos de otra. Esto
                es
                un punto a estudiar y mejorar. </p>

              <p>
                Por √∫ltimo, observamos que aumentar la complejidad del modelo solo empeora la performance, lo cual es,
                en
                parte, sorprendente, pero por otro lado tiene sentido, ya que el modelo base Inception_v3 es muy bueno
                haciendo su trabajo, y posiblemente el output del mismo no pueda ser mejorado, dej√°ndonos con la √∫nica
                tarea de clasificar las features en las x categor√≠as de nuestro problema.
              </p>
            </div>

            <div class="resumed">
              <p>Al analizar las estad√≠sticas, se observan mejoras en accuracy y loss en los modelos v1.2 y v1.4, pero
                un aumento en val_loss sugiere overfitting, lo cual es comprensible debido al desuso de data
                augmentation y
                dropouts para prevenirlo. En el modelo v1.3, la ausencia de BatchNormalization mejor√≥ la performance,
                posiblemente porque esta capa es m√°s √∫til en etapas intermedias de modelos complejos.
              </p>
              <p>
                Adem√°s, las similitudes en val_accuracy entre los modelos podr√≠an deberse a errores de etiquetado en las
                im√°genes de validaci√≥n, lo que limita el rendimiento m√°ximo alcanzable. Finalmente, aumentar la
                complejidad del modelo empeora su rendimiento, lo que refuerza la idea de que Inception_v3 ya realiza un
                excelente trabajo detectando features, dejando poca mejora posible.</p>
            </div>

            <h3 class="orange_title major">Estad√≠sticas del modelo seleccionado</h3>
            <p style="margin-bottom: 20px">
              El modelo ganador fue el v1.3. <a class="a-custom" target="_blank"
                href="https://colab.research.google.com/drive/1uU5ySJ_FRQYYXtaBswYEyEkJcovputsj?usp=sharing">En el
                Colab</a> se puede observar el c√≥digo completo, explicado en detalle;
              recomiendo darle una vichada. A continuaci√≥n, se presentan algunas estad√≠sticas del modelo:
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 25px; background-color: #313345">
              <span class=" image fit" style="margin: 0px;">
                <h5 style="margin: 0px; margin-left: 7px; margin-bottom: 15px;">Entrenamiento inicial</h5>
                <img src="images/ABO/train v1.3.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 19px;">
                  A diferencia de los otros modelos, para entrenar este se aument√≥ de 20 epochs a 40 para exprimir un
                  poco
                  mas de performance. El entrenamiento demor√≥ 13 minutos aprox.
                </p>
              </span>
            </div>
            <div class="gtr-uniform home-images" style="margin-bottom: 50px; background-color: #313345">
              <span class=" image fit" style="margin: 0px;">
                <h5 style="margin: 0px; margin-left: 7px; margin-bottom: 15px;">Fine tunning</h5>
                <img src="images/ABO/fine v1.3.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 19px;">
                  De igual forma, se aumentaron los epochs en la etapa de fine-tuning a 25, aunque, como se puede
                  observar en el gr√°fico, a partir del epoch 10-15 se empiezan a notar signos de overfitting, con poca
                  mejora en los valores de val_accuracy y val_loss, que son los que nos interesan. El entrenamiento
                  demor√≥ 30 minutos aprox.
                </p>
              </span>
            </div>
            <div class="extended">
              <h5>Estad√≠sticas por categor√≠a</h5>
              <p>En la siguiente tabla se pueden observar los valores de Precision, Recall y F1
                para cada categoria, donde
                las primeras son las mas problem√°ticas</p>

              <table id="score-table_2">
                <thead>
                  <tr>
                    <th>Category</th>
                    <th style="position: relative">Precision
                      <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Precision mide cu√°ntas de las predicciones positivas son
                          correctas.</span>
                      </span>
                    </th>
                    <th style="position: relative">Recall
                      <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Recall mide cu√°ntos de los positivos reales fueron identificados
                          correctamente.</span>
                      </span>
                    </th>
                    <th style="position: relative">F1-Score
                      <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">F1 es la media arm√≥nica entre precisi√≥n y recall.</span>
                      </span>
                    </th>
                    <th style="position: relative">Support
                      <span class="tooltip-container">
                        <span class="info-icon">&#9432;</span>
                        <span class="tooltiptext">Support es el n√∫mero total de ocurrencias de una clase espec√≠fica en
                          el
                          conjunto de datos.</span>
                      </span>
                    </th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td>HEALTH_PERSONAL_CARE</td>
                    <td>0.71</td>
                    <td>0.57</td>
                    <td>0.63</td>
                    <td>83</td>
                  </tr>
                  <tr>
                    <td>SHOES</td>
                    <td>0.80</td>
                    <td>0.68</td>
                    <td>0.74</td>
                    <td>66</td>
                  </tr>
                  <tr>
                    <td>LUGGAGE</td>
                    <td>0.80</td>
                    <td>0.67</td>
                    <td>0.73</td>
                    <td>83</td>
                  </tr>
                  <tr>
                    <td>ACCESSORY</td>
                    <td>0.85</td>
                    <td>0.70</td>
                    <td>0.77</td>
                    <td>76</td>
                  </tr>
                  <tr>
                    <td>CHAIR</td>
                    <td>0.82</td>
                    <td>0.70</td>
                    <td>0.76</td>
                    <td>80</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>OUTDOOR_LIVING</td>
                    <td>0.81</td>
                    <td>0.69</td>
                    <td>0.75</td>
                    <td>81</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BISS</td>
                    <td>0.69</td>
                    <td>0.63</td>
                    <td>0.66</td>
                    <td>73</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BEAUTY</td>
                    <td>0.68</td>
                    <td>0.65</td>
                    <td>0.67</td>
                    <td>75</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>OFFICE_PRODUCTS</td>
                    <td>0.67</td>
                    <td>0.65</td>
                    <td>0.66</td>
                    <td>83</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>WASTE_BAG</td>
                    <td>0.86</td>
                    <td>0.90</td>
                    <td>0.88</td>
                    <td>69</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>NUTRITIONAL_SUPPLEMENT</td>
                    <td>0.71</td>
                    <td>0.82</td>
                    <td>0.76</td>
                    <td>74</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SKIN_CLEANING_AGENT</td>
                    <td>0.78</td>
                    <td>0.82</td>
                    <td>0.80</td>
                    <td>93</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>AUTO_ACCESSORY</td>
                    <td>0.69</td>
                    <td>0.85</td>
                    <td>0.76</td>
                    <td>65</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>VITAMIN</td>
                    <td>0.82</td>
                    <td>0.75</td>
                    <td>0.79</td>
                    <td>85</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HOME_BED_AND_BATH</td>
                    <td>0.86</td>
                    <td>0.74</td>
                    <td>0.80</td>
                    <td>74</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SHELF</td>
                    <td>0.89</td>
                    <td>0.76</td>
                    <td>0.82</td>
                    <td>87</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>FOOD_SERVICE_SUPPLY</td>
                    <td>0.75</td>
                    <td>0.82</td>
                    <td>0.79</td>
                    <td>78</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>TOOLS</td>
                    <td>0.84</td>
                    <td>0.78</td>
                    <td>0.81</td>
                    <td>86</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>COFFEE</td>
                    <td>0.85</td>
                    <td>0.91</td>
                    <td>0.88</td>
                    <td>76</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>WALLET</td>
                    <td>0.83</td>
                    <td>0.93</td>
                    <td>0.88</td>
                    <td>70</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>NECKLACE</td>
                    <td>0.99</td>
                    <td>1.00</td>
                    <td>0.99</td>
                    <td>83</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BATTERY</td>
                    <td>0.96</td>
                    <td>0.95</td>
                    <td>0.96</td>
                    <td>83</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HANDBAG</td>
                    <td>0.96</td>
                    <td>0.96</td>
                    <td>0.96</td>
                    <td>75</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BACKPACK</td>
                    <td>0.82</td>
                    <td>0.97</td>
                    <td>0.89</td>
                    <td>69</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BREAD</td>
                    <td>0.97</td>
                    <td>0.96</td>
                    <td>0.96</td>
                    <td>70</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BED</td>
                    <td>0.86</td>
                    <td>0.88</td>
                    <td>0.87</td>
                    <td>73</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>BOOT</td>
                    <td>0.89</td>
                    <td>0.95</td>
                    <td>0.92</td>
                    <td>86</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>CABINET</td>
                    <td>0.90</td>
                    <td>0.91</td>
                    <td>0.90</td>
                    <td>95</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>CHARGING_ADAPTER</td>
                    <td>0.93</td>
                    <td>0.91</td>
                    <td>0.92</td>
                    <td>81</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>CLEANING_AGENT</td>
                    <td>0.89</td>
                    <td>0.87</td>
                    <td>0.88</td>
                    <td>82</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>DESK</td>
                    <td>0.91</td>
                    <td>0.90</td>
                    <td>0.90</td>
                    <td>79</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>DRINKING_CUP</td>
                    <td>0.92</td>
                    <td>0.95</td>
                    <td>0.94</td>
                    <td>76</td>
                  </tr>
                  <tr>
                    <td>EARRING</td>
                    <td>0.97</td>
                    <td>0.95</td>
                    <td>0.96</td>
                    <td>88</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>FLAT_SHEET</td>
                    <td>0.91</td>
                    <td>0.91</td>
                    <td>0.91</td>
                    <td>66</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>FURNITURE_COVER</td>
                    <td>0.88</td>
                    <td>0.93</td>
                    <td>0.90</td>
                    <td>84</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HARDWARE_HANDLE</td>
                    <td>0.87</td>
                    <td>0.95</td>
                    <td>0.91</td>
                    <td>62</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HAT</td>
                    <td>0.86</td>
                    <td>0.88</td>
                    <td>0.87</td>
                    <td>84</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HEADBOARD</td>
                    <td>0.94</td>
                    <td>0.93</td>
                    <td>0.94</td>
                    <td>86</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HEADPHONES</td>
                    <td>0.96</td>
                    <td>0.94</td>
                    <td>0.95</td>
                    <td>87</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>HERB</td>
                    <td>0.99</td>
                    <td>0.94</td>
                    <td>0.96</td>
                    <td>71</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>LAMP</td>
                    <td>0.89</td>
                    <td>0.94</td>
                    <td>0.92</td>
                    <td>70</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>LEGUME</td>
                    <td>0.96</td>
                    <td>0.99</td>
                    <td>0.97</td>
                    <td>88</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>LIGHT_BULB</td>
                    <td>0.91</td>
                    <td>0.97</td>
                    <td>0.94</td>
                    <td>62</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>LIGHT_FIXTURE</td>
                    <td>0.90</td>
                    <td>0.89</td>
                    <td>0.90</td>
                    <td>84</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>OTTOMAN</td>
                    <td>0.85</td>
                    <td>0.88</td>
                    <td>0.86</td>
                    <td>83</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>PET_SUPPLIES</td>
                    <td>0.92</td>
                    <td>0.79</td>
                    <td>0.85</td>
                    <td>72</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>PILLOW</td>
                    <td>0.87</td>
                    <td>0.98</td>
                    <td>0.92</td>
                    <td>87</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>PLANTER</td>
                    <td>0.88</td>
                    <td>0.99</td>
                    <td>0.93</td>
                    <td>80</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>PORTABLE_ELECTRONIC_DEVICE_COVER</td>
                    <td>0.96</td>
                    <td>0.87</td>
                    <td>0.91</td>
                    <td>84</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>RING</td>
                    <td>1.00</td>
                    <td>0.94</td>
                    <td>0.97</td>
                    <td>88</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>RUG</td>
                    <td>0.98</td>
                    <td>0.97</td>
                    <td>0.97</td>
                    <td>90</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SAFETY_SUPPLY</td>
                    <td>0.89</td>
                    <td>0.84</td>
                    <td>0.86</td>
                    <td>83</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SANDAL</td>
                    <td>0.87</td>
                    <td>0.93</td>
                    <td>0.90</td>
                    <td>80</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SAUTE_FRY_PAN</td>
                    <td>0.96</td>
                    <td>0.95</td>
                    <td>0.96</td>
                    <td>83</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SCREEN_PROTECTOR</td>
                    <td>0.96</td>
                    <td>0.99</td>
                    <td>0.97</td>
                    <td>87</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SKIN_MOISTURIZER</td>
                    <td>0.91</td>
                    <td>0.89</td>
                    <td>0.90</td>
                    <td>87</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SOFA</td>
                    <td>0.79</td>
                    <td>0.86</td>
                    <td>0.82</td>
                    <td>86</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>STOOL_SEATING</td>
                    <td>0.96</td>
                    <td>0.96</td>
                    <td>0.96</td>
                    <td>79</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>STORAGE_BINDER</td>
                    <td>0.93</td>
                    <td>0.97</td>
                    <td>0.95</td>
                    <td>69</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>STORAGE_HOOK</td>
                    <td>0.94</td>
                    <td>0.97</td>
                    <td>0.95</td>
                    <td>90</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>SUITCASE</td>
                    <td>0.87</td>
                    <td>0.95</td>
                    <td>0.91</td>
                    <td>80</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>TABLE</td>
                    <td>0.82</td>
                    <td>0.79</td>
                    <td>0.80</td>
                    <td>84</td>
                  </tr>
                  <tr class="cat_stats">
                    <td>TEA</td>
                    <td>0.87</td>
                    <td>0.96</td>
                    <td>0.91</td>
                    <td>70</td>
                  </tr>
                  <tr class="cat_stats">
                    <td><strong>Accuracy</strong></td>
                    <td colspan="4">0.88</td>
                  </tr>
                  <tr class="cat_stats">
                    <td><strong>Macro avg</strong></td>
                    <td>0.87</td>
                    <td>0.88</td>
                    <td>0.87</td>
                    <td>5167</td>
                  </tr>
                  <tr class="cat_stats">
                    <td><strong>Weighted avg</strong></td>
                    <td>0.88</td>
                    <td>0.88</td>
                    <td>0.87</td>
                    <td>5167</td>
                  </tr>
                </tbody>
              </table>


              <button id="show-more-table-btn" onclick="showMoreStats()"
                style="margin-top: -20px; margin-bottom: 60px">...expandir</button>
            </div>

            <h3 class="orange_title major">Modelo en acci√≥n</h3>
            <p style="margin-bottom: 20px">Se cre√≥ un espacio en HuggingFace Spaces para tener el modelo activo
              utilizando Gradio de forma constante, para poder ser utilizado en cualquier momento. Puedes usarlo aqu√≠
              abajo, subiendo una foto que encuentres en internet, o incluso fotografiando algo con tu dispositivo!</p>

            <div style="text-align: center;">
              <iframe allow="camera" src="https://nicolaspavon-amazon-classification.hf.space" frameborder="0"
                class="gradio"></iframe>
            </div>

            <p class="extended" style="margin-bottom: 20px; margin-top: 10px;">Aqu√≠ dejo las categor√≠as m√°s
              frecuentemente accesibles (en
              mi opini√≥n), pero puedes fotografiar cualquier objeto de <a class="a-custom" href="#categorias">las 65
                categor√≠as</a> para probar el modelo.</p>
            <p class="resumed" style="margin-bottom: 20px; margin-top: 10px;">Aqu√≠ dejo las categor√≠as m√°s
              frecuentemente accesibles (en
              mi opini√≥n), pero puedes fotografiar cualquier objeto de las 65
              categor√≠as para probar el modelo.</p>
            <div class="category-group-2 extended" style="width: 100%;">
              <i class="variable_2">COFFEE</i>
              <i class="variable_2">TEA</i>
              <i class="variable_2">BREAD</i>
              <i class="variable_2">DRINKING_CUP</i>
              <i class="variable_2">HEADPHONES</i>
              <i class="variable_2">CHARGING_ADAPTER</i>
              <i class="variable_2">SHOES</i>
              <i class="variable_2">PILLOW</i>
              <i class="variable_2">CHAIR</i>
              <i class="variable_2">WALL_ART</i>
              <i class="variable_2">LAMP</i>
              <i class="variable_2">RING</i>
              <i class="variable_2">HAT</i>
              <i class="variable_2">BACKPACK</i>
              <i class="variable_2">SUITCASE</i>
              <i class="variable_2">PLANTER</i>
              <i class="variable_2">WALLET</i>
            </div>
            <div class="resumed">
              <h5 style="margin-bottom: 10px;">
                Categorias finales:
              </h5>
              <div class="categories-container" style="display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 40px;">
                <!-- Categor√≠as comunes diarias -->
                <div class="category-group" style="width: 100%;">
                  <i class="variable_2">COFFEE</i>
                  <i class="variable_2">TEA</i>
                  <i class="variable_2">BREAD</i>
                  <i class="variable_2">DRINKING_CUP</i>
                  <i class="variable_2">HEADPHONES</i>
                  <i class="variable_2">CHARGING_ADAPTER</i>
                  <i class="variable_2">SHOES</i>
                  <i class="variable_2">PILLOW</i>
                  <i class="variable_2">CHAIR</i>
                  <i class="variable_2">WALL_ART</i>
                  <i class="variable_2">LAMP</i>
                  <i class="variable_2">RING</i>
                  <i class="variable_2">HAT</i>
                  <i class="variable_2">BACKPACK</i>
                  <i class="variable_2">SUITCASE</i>
                  <i class="variable_2">PLANTER</i>
                  <i class="variable_2">WALLET</i>
                </div>

                <button id="show-more-btn-2" onclick="showMoreCategories()" style="margin-top: -20px;">...ver
                  m√°s</button>

                <!-- Comida y Salud -->
                <div class="category-group" style="display: none; width: 100%;">
                  <h5>Comida y Salud</h5>
                  <i class="variable_2">LEGUME</i>
                  <i class="variable_2">HERB</i>
                  <i class="variable_2">HEALTH_PERSONAL_CARE</i>
                  <i class="variable_2">SKIN_CLEANING_AGENT</i>
                  <i class="variable_2">SKIN_MOISTURIZER</i>
                  <i class="variable_2">BEAUTY</i>
                  <i class="variable_2">VITAMIN</i>
                  <i class="variable_2">NUTRITIONAL_SUPPLEMENT</i>
                </div>

                <!-- Muebles -->
                <div class="category-group" style="display: none; width: 100%;">
                  <h5>Muebles</h5>
                  <i class="variable_2">SHELF</i>
                  <i class="variable_2">CABINET</i>
                  <i class="variable_2">DESK</i>
                  <i class="variable_2">TABLE</i>
                  <i class="variable_2">HEADBOARD</i>
                  <i class="variable_2">BED</i>
                  <i class="variable_2">OTTOMAN</i>
                  <i class="variable_2">STOOL_SEATING</i>
                  <i class="variable_2">SOFA</i>
                </div>

                <!-- Decoraci√≥n y Ropa de Cama -->
                <div class="category-group" style="display: none; width: 100%;">
                  <h5>Decoraci√≥n y Ropa de Cama</h5>
                  <i class="variable_2">RUG</i>
                  <i class="variable_2">FLAT_SHEET</i>
                  <i class="variable_2">FURNITURE_COVER</i>
                  <i class="variable_2">LIGHT_FIXTURE</i>
                </div>

                <!-- Accesorios y Joyas -->
                <div class="category-group" style="display: none; width: 100%;">
                  <h5>Accesorios y Joyas</h5>
                  <i class="variable_2">NECKLACE</i>
                  <i class="variable_2">EARRING</i>
                  <i class="variable_2">ACCESSORY</i>
                  <i class="variable_2">HANDBAG</i>
                  <i class="variable_2">BOOT</i>
                  <i class="variable_2">SANDAL</i>
                  <i class="variable_2">PORTABLE_ELECTRONIC_DEVICE_COVER</i>
                  <i class="variable_2">CELLULAR_PHONE_CASE</i>
                  <i class="variable_2">SCREEN_PROTECTOR</i>
                </div>

                <!-- Art√≠culos de Oficina y Limpieza -->
                <div class="category-group" style="display: none; width: 100%;">
                  <h5>Art√≠culos de Oficina y Limpieza</h5>
                  <i class="variable_2">OFFICE_PRODUCTS</i>
                  <i class="variable_2">STORAGE_BINDER</i>
                  <i class="variable_2">STORAGE_HOOK</i>
                  <i class="variable_2">CLEANING_AGENT</i>
                  <i class="variable_2">BATTERY</i>
                </div>

                <!-- Otros -->
                <div class="category-group" style="display: none; width: 100%;">
                  <h5>Otros</h5>
                  <i class="variable_2">AUTO_ACCESSORY</i>
                  <i class="variable_2">TOOLS</i>
                  <i class="variable_2">SAFETY_SUPPLY</i>
                  <i class="variable_2">FOOD_SERVICE_SUPPLY</i>
                  <i class="variable_2">BISS</i>
                  <i class="variable_2">LIGHT_BULB</i>
                  <i class="variable_2">OUTDOOR_LIVING</i>
                  <i class="variable_2">PET_SUPPLIES</i>
                </div>
              </div>
            </div>

            <p>
              En <a class="a-custom" href="https://colab.research.google.com/drive/1uU5ySJ_FRQYYXtaBswYEyEkJcovputsj#scrollTo=WKmy4s-RAc1K&line=4&uniqifier=1
              ">el colab</a> se pueden observar las pruebas que se hicieron para validar el modelo. Por un lado se
              probaron im√°genes ya vistas por el modelo en el entrenamiento, y luego se probaron im√°genes nuevas
              extraidas de amazon manualmente.
            </p>
            <p>En estas pruebas, se pueden observar los problemas previamente planteados. Las categorias <i
                class="variable">SUITCASE</i> y <i class="variable">LUGGAGE</i> se suelen confundir, la categoria <i
                class="variable">RUG</i> suele salir en fotos de sillones o mesas, entre otros.</p>
          </section>
        </div>
      </div>
      <div class="wrapper alt style4">
        <div class="inner">
          <section>
            <h3 class="orange_title major">Aspectos a mejorar</h3>
            <div>
              <p>Como se observ√≥ en la etapa de an√°lisis del dataset, una gran cantidad de im√°genes de <i
                  class="variable">RUG</i> contienen otros elementos como sillones, sillas, mesas, entre otros. Esto
                perjudica a la red, provocando que im√°genes de sillones, por ejemplo, sean clasificadas err√≥neamente
                bajo
                la categor√≠a <i class="variable">RUG</i>. Quitar estas im√°genes "gen√©ricas" del dataset mejorar√≠a
                notablemente la performance.</p>
              <p>En el dataset tambi√©n hay muchas im√°genes que muestran la textura o el color del objeto en venta, lo
                cual
                no aporta al entrenamiento de la red y probablemente sean la razon por la cual las estadisticas de loss
                y val_loss dan tan mal.</p>
              <p>La categor√≠a <i class="variable">FURNITURE_COVER</i> es muy similar a categor√≠as como <i
                  class="variable">SOFA</i> o <i class="variable">CHAIR</i>, causando clasificaciones err√≥neas.</p>
              <p>Como se coment√≥ en la etapa de <a class="a-custom" href="#inspeccion">inspecci√≥n del dataset</a>,
                existen
                varias categor√≠as que son muy gen√©ricas o confundibles. Como era de esperar, al probar el modelo con
                objetos de <i class="variable">SUITCASE</i> y <i class="variable">LUGGAGE</i>, suele confundirse en la
                clasificaci√≥n. De igual forma ocurre con <i class="variable">NUTRITIONAL_SUPPLEMENT</i> ‚Üî <i
                  class="variable">VITAMINS</i> ‚Üî <i class="variable">HEALTH_PERSONAL_CARE</i>, las cuales suelen ser
                im√°genes de frascos. En las <a class="a-custom" href="#score-table_2">estad√≠sticas del modelo</a> se
                puede
                observar la mala performance que tienen estas categor√≠as, debido a su similitud.</p>
              <p>Eliminar o unificar algunas de estas categor√≠as mejorar√≠a la mayor√≠a de los problemas que tiene el
                modelo.</p>
            </div>
            <div class="extended">
              <h3 class="orange_title major">Cosas que no funcionaron</h3>
              <h5>Clustering de macro-categorias</h5>
              <p>En un principio, se asoci√≥ la mala performance del modelo a la gran cantidad de categor√≠as. Por esta
                raz√≥n, se plante√≥ la posibilidad de crear un modelo gen√©rico encargado de clasificar dentro de 4-5
                macro-categor√≠as, y luego aplicar otro submodelo para cada macro-categor√≠a, encargado de identificar la
                categor√≠a final. Para esto, incluso se utiliz√≥ una t√©cnica de clustering similar a la utilizada en el
                balanceo del dataset, que agrup√≥ las categor√≠as similares para luego, a partir de estos grupos, generar
                las macro-categor√≠as. A continuaci√≥n, se puede observar el gr√°fico generado para la agrupaci√≥n:
              </p>
              <div class="gtr-uniform home-images" style="margin-bottom: 10px">
                <span class=" image fit" style="margin: 0px;"><img src="images/ABO/class clustering.png" alt="" />
                  <p style="margin-bottom: 0px; margin-top: 10px;"><i>Agrupaciones de categorias por similitud</i></p>
                </span>
              </div>
              <p>Como se puede observar, agrup√≥ exitosamente categor√≠as como <i class="variable">SOFA</i>, <i
                  class="variable">RUG</i>, <i class="variable">CHAIR</i> y otras dentro de una posible macro-categor√≠a
                <i class="variable">FURNITURE</i> (rama verde). De igual forma, ocurre con otras categor√≠as similares.
              </p>
              <p>Si bien esta idea parec√≠a prometedora, se observ√≥ que el modelo era capaz de trabajar exitosamente con
                las
                65 categor√≠as, por lo que esta idea qued√≥ obsoleta.
              </p>
              <h5>Im√°genes en blanco y negro</h5>
              <p>Se intento pasar las imagenes a blanco y negro, ya que los colores no deber√≠an hacer la diferencia
                entre
                una
                categoria u otra. sin embargo no se not√≥ mejora, aunque quiz√°s fue por un error de implementaci√≥n.</p>
            </div>
          </section>
        </div>
      </div>
      <div id="conclusions" class="wrapper style2">
        <div class="inner">

          <section>

            <h2 class="white-big major">Conclusiones</h2>
            <p>En este proyecto logramos observar la eficiencia de las t√©cnicas de transfer learning y
              fine-tuning, y destacamos la importancia de un an√°lisis exhaustivo del dataset, logrando un modelo
              eficiente a pesar de
              las limitaciones encontradas. Aunque hay √°reas de mejora, los
              resultados demuestran el valor de un enfoque incremental y constante experimentaci√≥n para optimizar
              modelos
              de deep learning.</p>
            <p>
              Gracias a Juan Kurucz por la orientaci√≥n, y a mis compa√±eros de proyecto por la ayuda al inicio del mismo,
              Tom√°s Rama,
              Mat√≠as Cabrera,
              Mauricio G√≥mez y
              Agust√≠n Lorenzo

            </p>
            <p>
              Eso es todo, gracias por tu tiempo! Si tienes alguna duda o comentario d√©jamelo saber aqu√≠ abajo üôè
            </p>
          </section>

        </div>
      </div>
    </section>

    <!-- Footer -->
    <section id="footer"></section>
  </div>

  <!-- Scripts -->
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/jquery.scrollex.min.js"></script>
  <script src="assets/js/browser.min.js"></script>
  <script src="assets/js/breakpoints.min.js"></script>
  <script src="assets/js/util.js"></script>
  <script src="assets/js/main.js"></script>
  <script src="scripts/menu.js"></script>
  <script src="scripts/footer.js"></script>

  <script>
    function applyColorToCell() {
      const table = document.getElementById('score-table');
      const rows = table.getElementsByTagName('tr');

      for (let i = 1; i < rows.length; i++) {
        const cells = rows[i].getElementsByTagName('td');

        const accuracy = parseFloat(cells[6].innerText);
        const loss = parseFloat(cells[7].innerText);
        const valAccuracy = parseFloat(cells[8].innerText);
        const valLoss = parseFloat(cells[9].innerText);

        // For accuracy and val_accuracy (higher is better)
        cells[6].style.backgroundColor = getGreenToRedGradient(accuracy, true);
        cells[8].style.backgroundColor = getGreenToRedGradient(valAccuracy, true);

        // For loss and val_loss (lower is better)
        cells[7].style.backgroundColor = getGreenToRedGradient(loss, false);
        cells[9].style.backgroundColor = getGreenToRedGradient(valLoss, false);
      }
    }

    function applyColorToCell_2() {
      const table = document.getElementById('score-table_2');
      const rows = table.getElementsByTagName('tr');
      console.log(rows.length)


      for (let i = 1; i < rows.length; i++) {
        const cells = rows[i].getElementsByTagName('td');
        console.log(cells)

        const precision = parseFloat(cells[1].innerText);
        const recall = parseFloat(cells[2].innerText);
        const f1 = parseFloat(cells[3].innerText);

        // For accuracy and val_accuracy (higher is better)
        cells[1].style.backgroundColor = getGreenToRedGradient(precision, true);
        cells[2].style.backgroundColor = getGreenToRedGradient(recall, true);
        cells[3].style.backgroundColor = getGreenToRedGradient(f1, true);
      }
    }

    function getGreenToRedGradient(value, higherIsBetter) {
      const colors = [
        { r: 0, g: 128, b: 0 },     // Green
        { r: 85, g: 170, b: 0 },    // Yellowgreen
        { r: 255, g: 255, b: 0 },   // Yellow
        { r: 255, g: 165, b: 0 },   // Orange
        { r: 255, g: 0, b: 0 },     // Red
        { r: 0, g: 0, b: 0 }        // Black
      ];

      // Adjust ratio for whether higher or lower is better
      let ratio = !higherIsBetter ? value : 1 - value;
      const step = 1 / (colors.length - 1);
      const index = Math.min(Math.floor(ratio / step), colors.length - 2);
      const color1 = colors[index];
      const color2 = colors[index + 1];

      const t = (ratio - index * step) / step;
      const r = Math.round(color1.r * (1 - t) + color2.r * t);
      const g = Math.round(color1.g * (1 - t) + color2.g * t);
      const b = Math.round(color1.b * (1 - t) + color2.b * t);

      return `rgb(${r}, ${g}, ${b}, 0.8)`; // Added opacity (0.8) to the colors
    }



    // Call the function to apply colors on page load
    applyColorToCell();
    applyColorToCell_2();
  </script>

</body>

</html>