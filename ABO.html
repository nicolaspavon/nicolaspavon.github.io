<!DOCTYPE html>
<!--
	Solid State by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<head>
  <title>ABO Image classification</title>
  <meta charset="utf-8" />
  <meta http-equiv="Permissions-Policy" content="camera=(self)">
  <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" charset="UTF-8" />
  <link rel="stylesheet" href="assets/css/main.css" />
  <noscript>
    <link rel="stylesheet" href="assets/css/noscript.css" />
  </noscript>
  <link rel="icon" href="images/icon.webp" type="image/x-icon" />
  <script>
    function showMoreCategories() {
      const groups = document.querySelectorAll('.category-group');
      groups.forEach((group, index) => {
        if (index !== 0) {
          group.style.display = 'block';
        }
      });
      document.getElementById('show-more-btn').style.display = 'none';
    }
  </script>
  <script>
    function showMoreStats() {
      const groups = document.querySelectorAll('.cat_stats');
      groups.forEach((group, index) => {
        if (index !== 0) {
          group.style.display = 'table-row';
        }
      });
      document.getElementById('show-more-table-btn').style.display = 'none';
    }
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function () {
      const progressBars = document.querySelectorAll(".progress-bar");

      // IntersectionObserver callback function
      const animateProgressBar = (entries, observer) => {
        entries.forEach(entry => {
          if (entry.isIntersecting) {
            const progressBar = entry.target;
            const value = parseFloat(progressBar.getAttribute("value"));
            progressBar.setAttribute("value", "0"); // Start from 0

            // Animate the progress bar value
            let currentValue = 0;
            const increment = value / 100; // Adjust this for speed
            const interval = setInterval(() => {
              currentValue += increment;
              if (currentValue >= value) {
                currentValue = value;
                clearInterval(interval);
              }
              progressBar.setAttribute("value", currentValue);
            }, 15); // Adjust this for smoothness

            // Stop observing the progress bar after animation is done
            observer.unobserve(progressBar);
          }
        });
      };

      // Create an IntersectionObserver
      const observer = new IntersectionObserver(animateProgressBar, {
        threshold: 0.1 // Trigger when 10% of the element is visible
      });

      // Observe each progress bar
      progressBars.forEach(bar => observer.observe(bar));
    });
  </script>

  <style>
    html {
      scroll-behavior: smooth;
    }

    h3 {
      color: #ee5f0f;
    }

    h4 {
      font-size: 0.9em;
    }

    h5 {
      font-size: 0.8em;
    }

    .white-big {
      font-size: 1.3em;
      text-align: center;
      margin-bottom: 20px;
      border-bottom: none !important;
    }

    .orange_title {
      font-size: 1.1em;
    }

    .variable {
      /* font-family: "Courier New", Courier, monospace; */
      background-color: #212430;
      padding: 2px 4px;
      color: #ee5f0f;
      font-size: 12px;
      font-weight: bold;
    }

    .variable_2 {
      /* font-family: "Courier New", Courier, monospace; */
      background-color: #212430;
      padding: 2px 4px;
      color: #ee5f0f;
      font-size: 16px;
      font-weight: bold;
    }

    .main-image {
      margin-right: 20px;
      height: auto;
      width: 100px;
      /* Maintain aspect ratio */
      object-fit: cover;
      /* Adjust the margin value as needed */
    }

    .oth-image {
      margin-right: 20px;
      height: auto;
      width: 100px;
      /* Maintain aspect ratio */
      object-fit: cover;
      /* Adjust the margin value as needed */
    }

    .gtr-uniform {
      display: flex;
      align-items: center;
      gap: 10px;
      /* Optional: Adds a gap between all columns */
    }

    .image-fit {
      width: 100%;
      max-width: 300px;
      height: auto;
      object-fit: cover;
    }

    /* Form Container */
    #contact-form {
      background-color: #2e3141;
      padding: 40px;
      border-radius: 8px;
    }

    /* Form Fields */
    .fields {
      display: flex;
      flex-wrap: wrap;
      gap: 20px;
    }

    .field {
      width: 100%;
    }

    /* Half-width fields for larger screens */
    .field.half {
      width: calc(50% - 10px);
    }

    .field.half.second {
      width: calc(50% - 10px);
      padding-right: 20px;
      padding-left: 0px;
    }

    /* Input and Textarea Styling */
    input[type="text"],
    input[type="email"],
    textarea {
      width: 100%;
      padding: 12px 15px;
      border: 1px solid #ccc;
      border-radius: 4px;
      background-color: #fff;
      color: #333;
      font-size: 16px;
    }

    /* Button Styling */
    .button {
      background-color: #ee5f0f;
      color: #fff;
      padding: 12px 30px;
      border: none;
      cursor: pointer;
      border-radius: 4px;
      font-size: 16px;
      text-align: center;
      display: block;
      margin: 0 auto;
      transition: background-color 0.3s;
      line-height: 0;
    }

    .button:hover {
      background-color: #ff7043;
    }

    /* Labels */
    label {
      color: #f0f0f0;
      font-size: 14px;
      margin-bottom: 8px;
      display: block;
    }

    /* Form Responsiveness */
    @media (max-width: 768px) {
      .field.half {
        width: 100%;
      }
    }

    /* Styling for the home images container */
    .home-images {
      display: flex;
      justify-content: space-between;
      background-color: #3a3d52;
      /* Background color for the row */
      padding: 20px;
      border-radius: 8px;
    }

    /* Styling for each image container */
    .home-image {
      flex: 1;
      margin: 0 10px;
      background-color: #4b4e63;
      /* Default background color for images */
      padding: 10px;
      border-radius: 8px;
      text-align: center;
    }

    /* Styling for the main image */
    .home-image.main-image {
      background-color: #5c5f75;
      max-width: 207px;
      /* Slightly different background color */
    }

    /* Styling for the images inside the containers */
    .home-image img {
      max-width: 100%;
      height: auto;
      border-radius: 4px;
    }

    .oth-row {
      display: flex;
      gap: 10px
    }

    .generic-cat {
      display: flex;
      flex-direction: row;
    }

    .gradio {
      width: 100%;
      height: auto;
      min-height: 483px;
    }

    /* Responsive adjustments */
    @media (max-width: 768px) {
      .home-images {
        flex-direction: column;
        gap: 20px;
      }

      .generic-cat {
        display: flex;
        flex-direction: column;
      }

      .home-image {
        margin: 10px 0;
      }

    }

    /* Responsive adjustments */
    @media (max-width: 878px) {

      .gradio {
        width: 100%;
        height: auto;
        min-height: 838px;
      }
    }

    /* Progress Bar Styling */
    .progress-bar {
      width: 100%;
      height: 8px;
      appearance: none;
      -webkit-appearance: none;
      margin-bottom: 5px;
    }

    /* Custom styles for different browsers */
    .progress-bar::-webkit-progress-bar {
      background-color: #f0f0f0;
      border-radius: 4px;
    }

    .progress-bar::-webkit-progress-value {
      background-color: #fe8d59;
      border-radius: 4px;
    }

    .progress-bar::-moz-progress-bar {
      background-color: #fe8d59;
      border-radius: 4px;
    }

    .category-group {
      margin-bottom: 20px;
    }

    .cat_stats {
      display: none;
    }

    #show-more-btn {
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 11px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
    }

    #show-more-table-btn {
      margin-top: 0px;
      padding: 10px;
      height: 25px;
      font-size: 13px;
      cursor: pointer;
      line-height: 5px;
      background-color: #ee5f0f;
      transition: background-color 0.3s;
      border-radius: 4px;
      margin-left: 3px;
      margin-bottom: 20px;
    }

    #show-more-btn:hover {
      background-color: #ff7043;
    }

    table {
      width: 100%;
      border-collapse: collapse;
      margin: 20px 0;
      font-family: Arial, sans-serif;
    }

    th,
    td {
      padding: 10px;
      text-align: center;
      border: 2px solid #666;
      font-weight: 600;
      /* Make text slightly bolder */
    }

    th {
      background-color: #2e3141;
      color: #ee5f0f;
      border-bottom: 3px solid #ee5f0f;
    }


    td.boolean-cell {
      font-size: 1.5em;
    }

    td.accuracy,
    td.loss,
    td.val_accuracy,
    td.val_loss {
      width: 70px;
      color: #fff;
      /* Ensure text contrast on colored background */
    }

    .green-check {
      color: #66bb6a;
    }

    .red-cross {
      color: #ff7043;
    }

    .separator {
      border: none;
      width: 1px;
    }

    td.separator {
      background-color: #2e3141;
      /* Set a consistent color for the separator column */
      border: none;
      /* Remove the border for the separator column */
    }

    tr:nth-child(odd) {
      background-color: #3a3b44;
      /* Softer color for odd rows */
    }

    tr:nth-child(even) {
      background-color: #404351;
      /* Slightly darker, but still subtle */
    }

    th,
    td {
      padding: 5px;
      /* Reduce padding to make rows less tall */
      text-align: center;
      border: 2px solid #666;
      font-weight: 600;
      /* Keep the bold text */
    }

    td.accuracy,
    td.loss,
    td.val_accuracy,
    td.val_loss {
      padding: 8px;
      /* Slightly larger padding for the score cells for readability */
    }

    tbody tr {
      height: 40px;
      /* Adjust this value to your preferred fixed row height */
    }

    td {
      vertical-align: middle;
      overflow: hidden;
      /* Prevent overflow from expanding the row */
      white-space: nowrap;
      /* Prevent text wrapping inside the cells */
      text-overflow: ellipsis;
      /* Add ellipsis if the text is too long */
    }

    table td {
      padding: 0em 0.35em;
    }

    table th {
      padding: 5px;
    }

    .a-custom {
      color: #ee5f0f;
      text-decoration: underline;
      cursor: pointer;
    }
  </style>
</head>

<body class="is-preload" style="
      background-image: linear-gradient(
          to top,
          rgba(46, 49, 65, 0.8),
          rgba(46, 49, 65, 0.8)
        ),
        url(images/ABO/cosas.webp);
    ">
  <!-- Page Wrapper -->
  <div id="page-wrapper">
    <!-- Header -->
    <header id="header">
      <a href="index.html">
        <h1>Nicolás Pavón</h1>
      </a>
      <nav>
        <a href="ABO-eng.html">ENG</a>
        <a href="#menu">Menú</a>
      </nav>
    </header>

    <!-- Menu -->
    <nav id="menu"></nav>

    <!-- Wrapper -->
    <section id="wrapper">
      <header id="ABO-header">
        <div class="inner">
          <h2>Clasificando imagenes de Amazon</h2>
        </div>
      </header>

      <!-- Content -->
      <div class="wrapper">
        <div class="inner">
          <section>
            <h3 class="orange_title major">El problema</h3>
            <p>
              En los últimos 20 años, el comercio electrónico ha crecido exponencialmente. Basta con observar el poder y
              el tamaño de sitios como Amazon, Alibaba o incluso Mercado Libre para darse cuenta de la importancia que
              tienen hoy en día. A partir de esto, podemos concluir que, si hay algo que tienen estos gigantes de la
              informática, es una enorme cantidad de datos, entre ellos, muchas imágenes. Sin embargo, los datos no
              sirven de nada si no se pueden interpretar y trabajar, por lo que es útil poder clasificarlos para darles
              un uso adecuado y sacarles todo el provecho posible.
            </p>

            <h3 class="orange_title major">Los datos</h3>
            <p>
              Entre todos los conjuntos de datos disponibles, nos topamos con uno <i>interesante</i>, el <a
                href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">Amazon Berkeley Objects (ABO)
                Dataset.</a> Este conjunto de datos nos proporciona imágenes de aproximadamente 147,000 productos de
              Amazon, con su correspondiente metadata, que incluye su categoría, color, palabras clave, marca, nombre,
              modelo, entre otros. Además, ofrece renders en 3D y algunos otros detalles interesantes. Si bien aún no
              hemos explorado los datos en profundidad para determinar su pureza, apreciamos el hecho de que provienen
              de Amazon, lo que hace que las imágenes sean ideales para este problema.
            </p>

            <h3 class="orange_title major">La tecnología</h3>
            <p>
              Si bien hoy en día suelen utilizarse los transformers para este tipo de problemas, en este caso
              utilizaremos redes convolucionales, partiendo de un modelo preentrenado como Inception-v3 y aplicando
              transfer learning, donde eliminaremos las capas superiores de clasificación y añadiremos nuevas capas
              especializadas para esta tarea. Por último, aplicaremos fine-tuning para mejorar el rendimiento. El código
              fue desarrollado en Google Colab.
            </p>

            <h3 class="orange_title major">El objetivo</h3>
            <p>
              Nuestro objetivo es clasificar el producto en la imagen, asumiendo que la imagen corresponde a un producto
              de comercio electrónico. Tomando esto en cuenta y analizando el conjunto de datos, observamos la propiedad
              <i class="variable">product_type</i>, la cual tiene alrededor de 574 clases que varían en nivel de
              precisión, desde "RING" hasta "BISS" (Business, Industrial, and Scientific Supplies). Partiremos de esta
              propiedad del conjunto de datos para entrenar nuestro modelo.
            </p>
          </section>
        </div>
      </div>
      <div class="wrapper alt style4">
        <div class="inner">
          <section>
            <h2 class="white-big major">Informacion y estructura del dataset</h2>
            <h3 class="orange_title major">Estructura del dataset</h3>
            <p>
              <a href="https://amazon-berkeley-objects.s3.amazonaws.com/index.html">El conjunto de datos</a> cuenta con
              varios archivos para descargar, de los cuales nos interesan <i class="variable">listings.tar</i> (listado
              de productos y metadata) e <i class="variable">images-small.tar</i> (catálogo de imágenes reescaladas a un
              máximo de 256 píxeles). <br /><br /> El archivo <i class="variable">listings.tar</i> contiene 15 archivos
              .json, cada uno con una lista de objetos, siendo cada objeto un producto de Amazon. Utilizaremos un script
              para pasar la información relevante de estos objetos a archivos .csv, para que sean más cómodos de
              trabajar. Los objetos tienen una serie de atributos, de los cuales nos interesarán <b><i>item_id</i></b>,
              <b><i>product_type</i></b>, <b><i>main_image_id</i></b> y <b><i>other_image_id</i></b>
            </p>
            <h3 class="orange_title major">Atributos del dataset y estadisticas</h3>
            <p>
              Una vez que tenemos el archivo .csv inicial, procedemos a observar la distribución de las clases:
            </p>

            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS inicial desb.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset inicial</i></p>
              </span>
            </div>

            <p>Como se ve en la imagen, el conjunto de datos está totalmente desbalanceado, con muchos ejemplos para
              ciertas categorías y casi ninguno en otras. Al observar los datos en detalle, vemos que hay 574
              categorías, de las cuales 460 tienen menos de 100 ejemplos. Esto es un problema, ya que necesitamos una
              buena cantidad de imágenes por categoría para poder identificar ese tipo de objetos con éxito, y solo 100
              o menos no son suficientes.</p>
            <p>
              Para lidiar con este problema, en un principio trabajaremos solo con las
              categorías que tengan más ejemplos, balanceando los mismos para evitar sesgos entre las categorías al
              momento de entrenar. Originalmente, se optó por trabajar con 170 categorías con al menos 50 ejemplos por
              categoría. Esto no dio resultado, por lo que se redujo el conjunto de datos a todas las categorías que
              tuvieran al menos 150 ejemplos, con un tope de 400. Esta fue una decisión algo arbitraria, por lo que, si
              se vuelve necesario, es posible encontrar una mejor selección de categorías y ejemplos.
            </p>
            <p style="margin-bottom: 10px;">Una vez realizados los filtros, podemos observar las estadísticas del
              conjunto de datos final:
            </p>

            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS min 150 max 400.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset simplificado</i></p>
              </span>
            </div>

            <p>En este conjunto de datos tenemos 80 categorías, mucho mejor balanceadas que las 574 del conjunto de
              datos inicial. Esto facilitará el trabajo, ya que la red neuronal final será más fácil de entrenar y
              tendrá un promedio de ejemplos por categoría considerablemente mayor.
            </p>

            <h3 class="orange_title major" id="inspeccion">Inspección del dataset</h3>
            <p>
              En este paso, analizaremos el conjunto de datos previamente refinado en busca de posibles problemas
              evidentes, entre los cuales encontramos:
            <h5>Categorias confundibles: </h5>
            <p>Estas categorías contienen objetos muy similares entre sí. Incluso, en algunos casos, la única forma de
              diferenciarlos es leyendo el texto que tiene el producto en la etiqueta. Esto es un problema, ya que para
              la red neuronal será
              difícil aprender las diferencias.</p>
            <ul>
              <li><i class="variable">ACCESORY</i> &#8596; <i class="variable">HAT</i></li>
              <li><i class="variable">STORAGE_HOOK</i> &#8596; <i class="variable">TOOLS</i></li>
              <li><i class="variable">NUTRITIONAL_SUPLEMENT</i> &#8596; <i class="variable">VITAMINS</i> &#8596; <i
                  class="variable">HEALTH_PERSONAL_CARE</i></li>
              <li><i class="variable">LUGGAGE</i> &#8596; <i class="variable">SUIT_CASE</i></li>
              <li><i class="variable">FINERING</i> &#8596; <i class="variable">RING</i></li>
              <li><i class="variable">FINENECKLACEBRACALETANKLET</i> &#8596; <i class="variable">NECKLACE</i></li>
              <li><i class="variable">FINEEARING</i> &#8596; <i class="variable">EARRING</i></li>
            </ul>
            <p>Exceptuando los casos de 'fine x' ↔ 'x', en un principio conservaremos estas categorías y observaremos si
              son efectivamente problemáticas al momento de clasificar. Para los casos 'fine x', nos quedaremos con los
              que no son "fine", ya que son más abarcativos y siguen preservando la forma general.</p>

            <h5>Categorias genericas: </h5>
            <p>Estas categorías contienen objetos muy variados, por lo que será más difícil entrenar a la red en busca
              de patrones compartidos. Si todos los objetos de una categoría varían en forma, no existe un conjunto de
              features o patrones que los unifique, y la red no podrá categorizar eficientemente. Solo sería posible
              lograrlo si cada subgrupo de objetos en esta categoría tuviera suficientes imágenes, pero como quizás de
              400 imágenes solo 90 pertenecen a uno de estos objetos, será muy difícil de entrenar. Por esta razón,
              estas categorías serán eliminadas del conjunto de datos.
            </p>
            <div class="generic-cat">
              <ul>
                <li><i class="variable">HOME</i></li>
                <li><i class="variable">WIRELESS_ACCESORY</i></li>
                <li><i class="variable">ACCESORY_OR_PART_OR_SUPPLY</i></li>
                <li><i class="variable">BABY_PRODUCT</i></li>
                <li><i class="variable">COMPUTER_ADDON</i></li>
                <li><i class="variable">GROCERY</i></li>
                <li><i class="variable">SPORTING_GOODS</i></li>
                <li><i class="variable">PANTRY</i></li>
                <li><i class="variable">KITCHEN</i></li>
                <li><i class="variable">JANITORY_SUPPLY</i></li>
                <li><i class="variable">HOMEFURNITURE_AND_DECOR</i></li>
                <li><i class="variable">HARDWARE</i></li>
              </ul>

              <div class="gtr-uniform home-images"
                style="flex-direction: column; align-items: flex-start; margin-bottom: 20px; margin-left: 16px; flex: 1; min-width: 0;">
                <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Ejemplos de productos en la categoria
                  <i class="variable">HOME</i>
                </h5>
                <div style="flex-direction: row; display: flex;">
                  <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                    <div class="oth-row">
                      <span>
                        <img src="images/ABO/HOME_3.jpg" alt="Home product example 2" />
                      </span>
                      <span>
                        <img src="images/ABO/HOME_2.jpg" alt="Home product example 1" />
                      </span>
                      <span>
                        <img src="images/ABO/HOME_1.jpg" alt="Home product example 1" />
                      </span>
                    </div>
                    <p style="margin: 0px;"><i>(No se parecen en nada)</i></p>
                  </div>
                </div>
              </div>
            </div>

            </p>
            <h3 class="orange_title major">Balanceo del dataset</h3>
            <p>
              Como se comentó previamente, un posible problema es el sesgo que puede generar el desbalance de ejemplos
              al momento de entrenar una red neuronal. Si en nuestra red tenemos mil ejemplos de zapatos y cien ejemplos
              de sillones, para la red las probabilidades de recibir un zapato son 10 veces mayores que las de recibir
              un sillón. En este caso, la red podría retornar siempre "zapato", acertando la mayoría de las veces. Esto
              afectaría la clasificación de forma bastante drástica, por lo que nos interesa tener el conjunto de datos
              lo más balanceado posible.

              En nuestro caso, tenemos varias categorías con menos de 400 ejemplos, que es el número ideal que queremos
              mantener en todas las categorías. Para lograr el balance deseado, tomaremos en cuenta las "other_images"
              disponibles por cada objeto que nos provee el dataset. Estas imágenes pueden ayudarnos a completar la
              cantidad de imágenes para aquellas categorías que lo necesiten.
            </p>
            <h5>Ejemplos satisfactorios</h5>
            <p>Luego de una no muy breve inspección, observamos casos satisfactorios en los que las "other_images" son
              suficientemente similares (pero no idénticas) al producto original.</p>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">SOFA</i></h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <img src="images/ABO/SOFA_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/SOFA_OTH_3.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/SOFA_OTH_1.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/SOFA_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <h5>Ejemplos problematicos</h5>
            <p>Sin embargo, también observamos imágenes que no son del producto en sí, sino de una tabla descriptiva, un
              color, o de una toma general en la que el objeto es casi indistinguible.</p>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">LEGUME</i></h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image" style="max-width: 170px;">
                  <span>
                    <img src="images/ABO/LEGUME_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/LEGUME_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_4.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/LEGUME_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>

            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Objeto en la categoria <i
                  class="variable">RUG</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <img src="images/ABO/RUG_MAIN.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <img src="images/ABO/RUG_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <img src="images/ABO/RUG_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <img src="images/ABO/RUG_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <p>Estos casos nos perjudican. Nos interesa tener cierta variabilidad en las imágenes para que nuestra red
              se vuelva más robusta, pero cuando tenemos imágenes demasiado complejas, o que ni siquiera contienen el
              objeto en sí, perjudican el entrenamiento de la red, ya que esta asociará patrones erróneos a la categoría
              en cuestión. ¡Recuerda el ejemplo de <i class="variable">RUG</i>! Será un problema en el futuro.
            </p>
            <p>Para superar este problema, haremos un filtrado de las "other_images" utilizando redes neuronales
              preentrenadas. En este caso, utilizaremos el modelo VGG16, quitando las capas de clasificación. Esto nos
              dejará una red que solo detecta features en una imagen, pero no la clasifica.

              Con esta red, procederemos a extraer las features de la imagen principal de cada objeto (main_image) y
              luego compararemos dichas features con las de cada una de las "other_images" de este objeto, obteniendo un
              coeficiente de similitud entre ellas. Este coeficiente nos indicará qué tan similares son las
              "other_images" a la imagen principal, asignando un valor muy bajo a aquellas que no sean similares.
            </p>
            <p style="margin-bottom: 10px;">Aqui observamos algunos ejemplos del uso de esta técnica:</p>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">SOFA</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>

                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/SOFA_MAIN.jpg" alt="" />
                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
              display: flex;
              flex-direction: column;
              height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                    
                      margin: 0px;
                      margin-bottom: -9px;
                      font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.861</i></p>
                      <progress value="0.8615963" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_1.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.640</i></p>
                      <progress value="0.6404396" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_2.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.599</i></p>
                      <progress value="0.5996146" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_3.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.196</i></p>
                      <progress value="0.1969997" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/SOFA_OTH_4.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">OTTOMAN</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>

                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/OTTOMAN-MAIN.jpg" alt="" />
                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
              display: flex;
              flex-direction: column;
              height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                    
                      margin: 0px;
                      margin-bottom: -9px;
                      font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.819</i></p>
                      <progress value="0.819" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.8198348.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.689</i></p>
                      <progress value="0.689" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.6890952.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.581</i></p>
                      <progress value="0.581" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.5811923.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.192</i></p>
                      <progress value="0.19274572" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/OTTOMAN-0.19274572.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>

            <p style="margin-bottom: 10px;">¡Genial! Vemos que funciona, sin embargo, encontramos algunos problemas::
            </p>
            <p>La categoría RUG nos complica un poco. Si observamos algunos ejemplos, veremos que la "main_image" suele
              contener la alfombra en una escena genérica, un poco "escondida". Esto causa que el coeficiente de
              similitud de las "other_images" sea muy bajo, dejando fuera muchas imágenes útiles.</p>
            <div class="gtr-uniform home-images"
              style="flex-direction: column; align-items: flex-start; margin-bottom: 20px">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Similarity scores del objeto <i
                  class="variable">RUG</i>
              </h5>
              <div class="generic-cat">
                <div class="col-4 home-image main-image">
                  <span>
                    <p style="display: flex;
                    margin: 0px;
                    margin-bottom: -9px;"><i>Similarity score:</i><i style="font-weight: bold; color:#ee5f0f;
                    margin-left: 5px;">1</i></p>
                    <progress value="1" max="1" class="progress-bar"></progress>
                    <img src="images/ABO/RUG-MAIN-SIM.jpg" alt="" />

                    <p style="margin: 0px;"><i>Main image</i></p>
                  </span>
                </div>
                <div class="row-4 home-image" style="align-self: center;
                display: flex;
                flex-direction: column;
                height: fit-content;">
                  <div class="oth-row">
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.273</i></p>
                      <progress value="0.27311817" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.27311817.jpg" alt="Home product example 2" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.213</i></p>
                      <progress value="0.21372926" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.21372926.jpg" alt="Home product example 1" />
                    </span>
                    <span>
                      <p style="
                      
                      margin: 0px;
                      margin-bottom: -9px; font-size: 19px; display: flex;"><i style="font-weight: bold; color:#ee5f0f;
                      margin-left: 5px;">0.187</i></p>
                      <progress value="0.18717194" max="1" class="progress-bar"></progress>
                      <img src="images/ABO/RUG-0.18717194.jpg" alt="Home product example 1" />
                    </span>
                  </div>
                  <p style="margin: 0px;"><i>Other images</i></p>
                </div>
              </div>
            </div>
            <p>Utilizaremos un threshold de 0.5 como criterio para seleccionar las "other_images", eligiendo aquellas
              que tengan un coeficiente de similitud mayor a este para completar las imágenes faltantes en una
              categoría. Sin embargo, en el caso de la categoría <i class="variable">RUG</i>, tomaremos un threshold de
              solo 0.2, ya que, debido a las características de las "main_images", la mayoría de las "other_images"
              quedarían fuera.
            </p>

            <h3 class="orange_title major">Dataset final</h3>
            <p>
              Por último, para terminar de armar el conjunto de datos y poder entrenar la red neuronal, debemos
              organizar las imágenes, agrupándolas por categoría. Una vez que conocemos los similarity scores de las
              "other_images", procedemos a mover todas las "main_images" a la carpeta de su categoría y completamos
              aquellas que tengan pocos ejemplos con las "other_images" que tengan mayor similarity score.
            </p>
            <p style="margin-bottom: 10px;">
              Este es el balance del dataset resultante, mucho mejor!
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/DS FINAL.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Dataset final</i></p>
              </span>
            </div>
            <p id="categorias">
              Este dataset cuenta con 65 categorías y aproximadamente 25,800 imágenes. Reconocemos que hay categorías
              que no alcanzaron las 400 imágenes debido a la falta de un buen similarity score, pero dado que aún tienen
              una cantidad considerable (>320), simplemente lo ignoraremos.
            </p>
            <h5 style="margin-bottom: 10px;">
              Categorias finales:
            </h5>
            <div class="categories-container" style="display: flex; flex-wrap: wrap; gap: 10px; margin-bottom: 40px;">
              <!-- Categorías comunes diarias -->
              <div class="category-group" style="width: 100%;">
                <i class="variable_2">COFFEE</i>
                <i class="variable_2">TEA</i>
                <i class="variable_2">BREAD</i>
                <i class="variable_2">DRINKING_CUP</i>
                <i class="variable_2">HEADPHONES</i>
                <i class="variable_2">CHARGING_ADAPTER</i>
                <i class="variable_2">SHOES</i>
                <i class="variable_2">PILLOW</i>
                <i class="variable_2">CHAIR</i>
                <i class="variable_2">WALL_ART</i>
                <i class="variable_2">LAMP</i>
                <i class="variable_2">RING</i>
                <i class="variable_2">HAT</i>
                <i class="variable_2">BACKPACK</i>
                <i class="variable_2">SUITCASE</i>
                <i class="variable_2">PLANTER</i>
                <i class="variable_2">WALLET</i>
              </div>

              <button id="show-more-btn" onclick="showMoreCategories()" style="margin-top: -20px;">...ver más</button>

              <!-- Comida y Salud -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Comida y Salud</h5>
                <i class="variable_2">LEGUME</i>
                <i class="variable_2">HERB</i>
                <i class="variable_2">HEALTH_PERSONAL_CARE</i>
                <i class="variable_2">SKIN_CLEANING_AGENT</i>
                <i class="variable_2">SKIN_MOISTURIZER</i>
                <i class="variable_2">BEAUTY</i>
                <i class="variable_2">VITAMIN</i>
                <i class="variable_2">NUTRITIONAL_SUPPLEMENT</i>
              </div>

              <!-- Muebles -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Muebles</h5>
                <i class="variable_2">SHELF</i>
                <i class="variable_2">CABINET</i>
                <i class="variable_2">DESK</i>
                <i class="variable_2">TABLE</i>
                <i class="variable_2">HEADBOARD</i>
                <i class="variable_2">BED</i>
                <i class="variable_2">OTTOMAN</i>
                <i class="variable_2">STOOL_SEATING</i>
                <i class="variable_2">SOFA</i>
              </div>

              <!-- Decoración y Ropa de Cama -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Decoración y Ropa de Cama</h5>
                <i class="variable_2">RUG</i>
                <i class="variable_2">FLAT_SHEET</i>
                <i class="variable_2">FURNITURE_COVER</i>
                <i class="variable_2">LIGHT_FIXTURE</i>
              </div>

              <!-- Accesorios y Joyas -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Accesorios y Joyas</h5>
                <i class="variable_2">NECKLACE</i>
                <i class="variable_2">EARRING</i>
                <i class="variable_2">ACCESSORY</i>
                <i class="variable_2">HANDBAG</i>
                <i class="variable_2">BOOT</i>
                <i class="variable_2">SANDAL</i>
                <i class="variable_2">PORTABLE_ELECTRONIC_DEVICE_COVER</i>
                <i class="variable_2">CELLULAR_PHONE_CASE</i>
                <i class="variable_2">SCREEN_PROTECTOR</i>
              </div>

              <!-- Artículos de Oficina y Limpieza -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Artículos de Oficina y Limpieza</h5>
                <i class="variable_2">OFFICE_PRODUCTS</i>
                <i class="variable_2">STORAGE_BINDER</i>
                <i class="variable_2">STORAGE_HOOK</i>
                <i class="variable_2">CLEANING_AGENT</i>
                <i class="variable_2">BATTERY</i>
              </div>

              <!-- Otros -->
              <div class="category-group" style="display: none; width: 100%;">
                <h5>Otros</h5>
                <i class="variable_2">AUTO_ACCESSORY</i>
                <i class="variable_2">TOOLS</i>
                <i class="variable_2">SAFETY_SUPPLY</i>
                <i class="variable_2">FOOD_SERVICE_SUPPLY</i>
                <i class="variable_2">BISS</i>
                <i class="variable_2">LIGHT_BULB</i>
                <i class="variable_2">OUTDOOR_LIVING</i>
                <i class="variable_2">PET_SUPPLIES</i>
              </div>
            </div>
          </section>
        </div>
      </div>

      <div class="wrapper style3">
        <div class="inner">
          <section>
            <h2 class="white-big major">Diseño y entrenamiento de la red neuronal</h2>
            <h3 class="orange_title major">Entrenamiento de la red</h3>
            <p>Lograr que la red tuviera un buen rendimiento fue difícil. Como se mencionó previamente, se optó por
              aplicar transfer learning, partiendo de un modelo preentrenado sin sus top layers (las capas de
              clasificación). Este modelo se encargaría de detectar las features o características principales en las
              imágenes, y luego sobre esto
              se agregarían capas personalizadas encargadas de clasificar estas features dentro de las 65 categorías
              posibles. Por último, se aplicaría fine-tuning para optimizar el rendimiento.
            </p>
            <p>En un principio, se optó por utilizar el modelo VGG-16, agregando varias capas para la clasificación (3
              capas dense y 1 capa de dropout). Este modelo tuvo un rendimiento muy pobre.</p>
            <p>Se optó por simplificar el problema reduciendo la cantidad de categorías y, además, utilizar
              Inception-v3. Aquí se empezaron a notar mejoras, sobre todo cuando se simplificó la etapa de
              clasificación, reduciéndola a 2 dense layers, 1 dropout y 1 BatchNormalization.</p>
            <p>Luego de varias iteraciones, se lograron métricas satisfactorias. El modelo más performante solo agrega
              una capa dense de 256 unidades, acompañada de un Dropout(0.4) y una capa de data augmentation con varias
              técnicas para evitar el overfitting. Sorprendentemente, esta red tan sencilla es de las más performantes.
              Por esto, podemos asumir que el modelo Inception-v3 ya hace un excelente trabajo al detectar las features
              en una imagen, dejándonos poco trabajo para completar el modelo.</p>
            <p>Una vez que encontramos un diseño de red eficiente, continuamos con las pruebas, estudiando qué beneficia
              al modelo y qué lo perjudica. En la siguiente tabla se pueden observar las métricas de los distintos
              diseños experimentados: </p>

            <div class="gtr-uniform home-images"
              style="margin-bottom: 10px; flex-direction: column; align-items: flex-start; background-color: #313345">
              <h5 style="margin: 0px; margin-left: 15px; margin-bottom: 5px;">Tabla comparativa de los modelos</h5>
              <table id="score-table" style="margin: 0px">
                <thead>
                  <tr>
                    <th>Version</th>
                    <th>Dense Layers</th>
                    <th>Data <br>Augmentation</th>
                    <th>BatchNorm</th>
                    <th>Dropout</th>
                    <th class="separator"></th>
                    <th>Accuracy</th>
                    <th>Loss</th>
                    <th>Val Accuracy</th>
                    <th>Val Loss</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="description">v1.1</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">✅</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.89</td>
                    <td class="loss">0.35</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.48</td>
                  </tr>
                  <tr>
                    <td class="description">v1.2</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">❌</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">✅</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.97</td>
                    <td class="loss">0.09</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.56</td>
                  </tr>
                  <tr>
                    <td class="description">v1.3</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">❌</td>
                    <td class="boolean-cell">✅</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.91</td>
                    <td class="loss">0.26</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.46</td>
                  </tr>
                  <tr>
                    <td class="description">v1.4</td>
                    <td>1x(256)</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">❌</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.95</td>
                    <td class="loss">0.15</td>
                    <td class="val_accuracy">0.86</td>
                    <td class="val_loss">0.51</td>
                  </tr>
                  <tr>
                    <td class="description">v2.1</td>
                    <td>1x(256) 1x(512)</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">✅x2</td>
                    <td class="boolean-cell">✅x2</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.83</td>
                    <td class="loss">0.57</td>
                    <td class="val_accuracy">0.84</td>
                    <td class="val_loss">0.54</td>
                  </tr>
                  <tr>
                    <td class="description">v2.2</td>
                    <td>1x(512) 1x(1024)</td>
                    <td class="boolean-cell">✅</td>
                    <td class="boolean-cell">✅x2</td>
                    <td class="boolean-cell">✅x2</td>
                    <td class="separator"></td>
                    <td class="accuracy">0.85</td>
                    <td class="loss">0.47</td>
                    <td class="val_accuracy">0.84</td>
                    <td class="val_loss">0.55</td>
                  </tr>
                  <!-- Add more rows as needed -->
                </tbody>
              </table>
              <p style="margin-bottom: 0px; margin-top: 0px;"><i style="font-size: 14px">Todos los modelos fueron
                  entrenados con 20 epochs en el
                  entrenamiento inicial y 15 en la etapa de
                  fine-tunning</i></p>
              </span>
            </div>
            <p> Analizando un poco estas estadísticas, podemos observar en los modelos v1.2 y v1.4 grandes mejoras en
              los valores de accuracy y loss, pero a la vez notamos valores de val_loss un poco peores, esto nos
              indica overfitting, lo cual tiene sentido. La capa de data augmentation busca hacer que nuestro modelo sea
              más robusto, alterando las imágenes de varias formas, como rotaciones aleatorias, cambios en el contraste
              o brillo, zooms aleatorios, etc. A su vez, el objetivo principal de las capas dropout es prevenir el
              overfitting, por lo que es entendible que empeore su performance.</p>

            <p>Por otra parte, observamos que el modelo v1.3, que carece de la capa BatchNormalization, tiene una mejora
              interesante en la performance. Si bien este tipo de capas son muy importantes y frecuentemente utilizadas
              en modelos de clasificación de imágenes, podemos atribuir esta baja en la performance al hecho de que se
              está utilizando en la etapa final de clasificación del modelo. Quizás sería más útil en una etapa
              intermedia de un modelo más complejo. </p>

            <p>Otro hecho interesante que podemos observar de las estadísticas es la similitud de performances entre
              modelos respecto al val_accuracy. Como podemos ver, todos los modelos tienen valores muy similares. Mi
              teoría es que esto se debe a que varias imágenes utilizadas para la validación están simplemente mal
              etiquetadas. Son casos similares a los de la categoría RUG, donde la primera imagen, además de contener la
              alfombra, también suele contener otros objetos como sillones, sillas, cuadros, etc.

              Teniendo esto en cuenta, podemos suponer que el modelo nunca será capaz de superar cierta performance,
              porque algunas imágenes están clasificadas bajo cierta categoría, pero contienen objetos de otra. Esto es
              un punto a estudiar y mejorar. </p>

            <p>
              Por último, observamos que aumentar la complejidad del modelo solo empeora la performance, lo cual es, en
              parte, sorprendente, pero por otro lado tiene sentido, ya que el modelo base Inception_v3 es muy bueno
              haciendo su trabajo, y posiblemente el output del mismo no pueda ser mejorado, dejándonos con la única
              tarea de clasificar las features en las x categorías de nuestro problema.
            </p>

            <h3 class="orange_title major">Estadísticas del modelo seleccionado</h3>
            <p style="margin-bottom: 20px">
              El modelo ganador fue el v1.3. En el Colab se puede observar el código completo, explicado en detalle;
              recomiendo darle una vichada. A continuación, se presentan algunas estadísticas del modelo:
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 25px; background-color: #313345">
              <span class=" image fit" style="margin: 0px;">
                <h5 style="margin: 0px; margin-left: 7px; margin-bottom: 15px;">Entrenamiento inicial</h5>
                <img src="images/ABO/train v1.3.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 19px;">
                  A diferencia de los otros modelos, para entrenar este se aumentó de 20 epochs a 40 para exprimir un
                  poco
                  mas de performance.
                </p>
              </span>
            </div>
            <div class="gtr-uniform home-images" style="margin-bottom: 50px; background-color: #313345">
              <span class=" image fit" style="margin: 0px;">
                <h5 style="margin: 0px; margin-left: 7px; margin-bottom: 15px;">Fine tunning</h5>
                <img src="images/ABO/fine v1.3.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 19px;">
                  De igual forma, se aumentaron los epochs en la etapa de fine-tuning a 25, aunque, como se puede
                  observar en el gráfico, a partir del epoch 10-15 se empiezan a notar signos de overfitting, con poca
                  mejora en los valores de val_accuracy y val_loss, que son los que nos interesan.
                </p>
              </span>
            </div>
            <h5>Estadísticas por categoría</h5>
            <p>En la siguiente tabla se pueden observar los valores de Precision, Recall y F1
              para cada categoria, donde
              las primeras son las que tienen peor performance</p>
            <p style="margin-bottom: 0px">Precision mide cuántas de las predicciones positivas son correctas.</p>
            <p style="margin-bottom: 0px">Recall mide cuántos de los positivos reales fueron identificados
              correctamente.</p>
            <p style="margin-bottom: 0px">F1 es la media armónica entre precisión y recall.</p>
            <p style="margin-bottom: 0px">Support es el número total de ocurrencias de una clase específica en el
              conjunto de datos.</p>

            <table id="score-table_2">
              <thead>
                <tr>
                  <th>Category</th>
                  <th>Precision</th>
                  <th>Recall</th>
                  <th>F1-Score</th>
                  <th>Support</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>HEALTH_PERSONAL_CARE</td>
                  <td>0.71</td>
                  <td>0.57</td>
                  <td>0.63</td>
                  <td>83</td>
                </tr>
                <tr>
                  <td>SHOES</td>
                  <td>0.80</td>
                  <td>0.68</td>
                  <td>0.74</td>
                  <td>66</td>
                </tr>
                <tr>
                  <td>LUGGAGE</td>
                  <td>0.80</td>
                  <td>0.67</td>
                  <td>0.73</td>
                  <td>83</td>
                </tr>
                <tr>
                  <td>ACCESSORY</td>
                  <td>0.85</td>
                  <td>0.70</td>
                  <td>0.77</td>
                  <td>76</td>
                </tr>
                <tr>
                  <td>CHAIR</td>
                  <td>0.82</td>
                  <td>0.70</td>
                  <td>0.76</td>
                  <td>80</td>
                </tr>
                <tr class="cat_stats">
                  <td>OUTDOOR_LIVING</td>
                  <td>0.81</td>
                  <td>0.69</td>
                  <td>0.75</td>
                  <td>81</td>
                </tr>
                <tr class="cat_stats">
                  <td>BISS</td>
                  <td>0.69</td>
                  <td>0.63</td>
                  <td>0.66</td>
                  <td>73</td>
                </tr>
                <tr class="cat_stats">
                  <td>BEAUTY</td>
                  <td>0.68</td>
                  <td>0.65</td>
                  <td>0.67</td>
                  <td>75</td>
                </tr>
                <tr class="cat_stats">
                  <td>OFFICE_PRODUCTS</td>
                  <td>0.67</td>
                  <td>0.65</td>
                  <td>0.66</td>
                  <td>83</td>
                </tr>
                <tr class="cat_stats">
                  <td>WASTE_BAG</td>
                  <td>0.86</td>
                  <td>0.90</td>
                  <td>0.88</td>
                  <td>69</td>
                </tr>
                <tr class="cat_stats">
                  <td>NUTRITIONAL_SUPPLEMENT</td>
                  <td>0.71</td>
                  <td>0.82</td>
                  <td>0.76</td>
                  <td>74</td>
                </tr>
                <tr class="cat_stats">
                  <td>SKIN_CLEANING_AGENT</td>
                  <td>0.78</td>
                  <td>0.82</td>
                  <td>0.80</td>
                  <td>93</td>
                </tr>
                <tr class="cat_stats">
                  <td>AUTO_ACCESSORY</td>
                  <td>0.69</td>
                  <td>0.85</td>
                  <td>0.76</td>
                  <td>65</td>
                </tr>
                <tr class="cat_stats">
                  <td>VITAMIN</td>
                  <td>0.82</td>
                  <td>0.75</td>
                  <td>0.79</td>
                  <td>85</td>
                </tr>
                <tr class="cat_stats">
                  <td>HOME_BED_AND_BATH</td>
                  <td>0.86</td>
                  <td>0.74</td>
                  <td>0.80</td>
                  <td>74</td>
                </tr>
                <tr class="cat_stats">
                  <td>SHELF</td>
                  <td>0.89</td>
                  <td>0.76</td>
                  <td>0.82</td>
                  <td>87</td>
                </tr>
                <tr class="cat_stats">
                  <td>FOOD_SERVICE_SUPPLY</td>
                  <td>0.75</td>
                  <td>0.82</td>
                  <td>0.79</td>
                  <td>78</td>
                </tr>
                <tr class="cat_stats">
                  <td>TOOLS</td>
                  <td>0.84</td>
                  <td>0.78</td>
                  <td>0.81</td>
                  <td>86</td>
                </tr>
                <tr class="cat_stats">
                  <td>COFFEE</td>
                  <td>0.85</td>
                  <td>0.91</td>
                  <td>0.88</td>
                  <td>76</td>
                </tr>
                <tr class="cat_stats">
                  <td>WALLET</td>
                  <td>0.83</td>
                  <td>0.93</td>
                  <td>0.88</td>
                  <td>70</td>
                </tr>
                <tr class="cat_stats">
                  <td>NECKLACE</td>
                  <td>0.99</td>
                  <td>1.00</td>
                  <td>0.99</td>
                  <td>83</td>
                </tr>
                <tr class="cat_stats">
                  <td>BATTERY</td>
                  <td>0.96</td>
                  <td>0.95</td>
                  <td>0.96</td>
                  <td>83</td>
                </tr>
                <tr class="cat_stats">
                  <td>HANDBAG</td>
                  <td>0.96</td>
                  <td>0.96</td>
                  <td>0.96</td>
                  <td>75</td>
                </tr>
                <tr class="cat_stats">
                  <td>BACKPACK</td>
                  <td>0.82</td>
                  <td>0.97</td>
                  <td>0.89</td>
                  <td>69</td>
                </tr>
                <tr class="cat_stats">
                  <td>BREAD</td>
                  <td>0.97</td>
                  <td>0.96</td>
                  <td>0.96</td>
                  <td>70</td>
                </tr>
                <tr class="cat_stats">
                  <td>BED</td>
                  <td>0.86</td>
                  <td>0.88</td>
                  <td>0.87</td>
                  <td>73</td>
                </tr>
                <tr class="cat_stats">
                  <td>BOOT</td>
                  <td>0.89</td>
                  <td>0.95</td>
                  <td>0.92</td>
                  <td>86</td>
                </tr>
                <tr class="cat_stats">
                  <td>CABINET</td>
                  <td>0.90</td>
                  <td>0.91</td>
                  <td>0.90</td>
                  <td>95</td>
                </tr>
                <tr class="cat_stats">
                  <td>CHARGING_ADAPTER</td>
                  <td>0.93</td>
                  <td>0.91</td>
                  <td>0.92</td>
                  <td>81</td>
                </tr>
                <tr class="cat_stats">
                  <td>CLEANING_AGENT</td>
                  <td>0.89</td>
                  <td>0.87</td>
                  <td>0.88</td>
                  <td>82</td>
                </tr>
                <tr class="cat_stats">
                  <td>DESK</td>
                  <td>0.91</td>
                  <td>0.90</td>
                  <td>0.90</td>
                  <td>79</td>
                </tr>
                <tr class="cat_stats">
                  <td>DRINKING_CUP</td>
                  <td>0.92</td>
                  <td>0.95</td>
                  <td>0.94</td>
                  <td>76</td>
                </tr>
                <tr>
                  <td>EARRING</td>
                  <td>0.97</td>
                  <td>0.95</td>
                  <td>0.96</td>
                  <td>88</td>
                </tr>
                <tr class="cat_stats">
                  <td>FLAT_SHEET</td>
                  <td>0.91</td>
                  <td>0.91</td>
                  <td>0.91</td>
                  <td>66</td>
                </tr>
                <tr class="cat_stats">
                  <td>FURNITURE_COVER</td>
                  <td>0.88</td>
                  <td>0.93</td>
                  <td>0.90</td>
                  <td>84</td>
                </tr>
                <tr class="cat_stats">
                  <td>HARDWARE_HANDLE</td>
                  <td>0.87</td>
                  <td>0.95</td>
                  <td>0.91</td>
                  <td>62</td>
                </tr>
                <tr class="cat_stats">
                  <td>HAT</td>
                  <td>0.86</td>
                  <td>0.88</td>
                  <td>0.87</td>
                  <td>84</td>
                </tr>
                <tr class="cat_stats">
                  <td>HEADBOARD</td>
                  <td>0.94</td>
                  <td>0.93</td>
                  <td>0.94</td>
                  <td>86</td>
                </tr>
                <tr class="cat_stats">
                  <td>HEADPHONES</td>
                  <td>0.96</td>
                  <td>0.94</td>
                  <td>0.95</td>
                  <td>87</td>
                </tr>
                <tr class="cat_stats">
                  <td>HERB</td>
                  <td>0.99</td>
                  <td>0.94</td>
                  <td>0.96</td>
                  <td>71</td>
                </tr>
                <tr class="cat_stats">
                  <td>LAMP</td>
                  <td>0.89</td>
                  <td>0.94</td>
                  <td>0.92</td>
                  <td>70</td>
                </tr>
                <tr class="cat_stats">
                  <td>LEGUME</td>
                  <td>0.96</td>
                  <td>0.99</td>
                  <td>0.97</td>
                  <td>88</td>
                </tr>
                <tr class="cat_stats">
                  <td>LIGHT_BULB</td>
                  <td>0.91</td>
                  <td>0.97</td>
                  <td>0.94</td>
                  <td>62</td>
                </tr>
                <tr class="cat_stats">
                  <td>LIGHT_FIXTURE</td>
                  <td>0.90</td>
                  <td>0.89</td>
                  <td>0.90</td>
                  <td>84</td>
                </tr>
                <tr class="cat_stats">
                  <td>OTTOMAN</td>
                  <td>0.85</td>
                  <td>0.88</td>
                  <td>0.86</td>
                  <td>83</td>
                </tr>
                <tr class="cat_stats">
                  <td>PET_SUPPLIES</td>
                  <td>0.92</td>
                  <td>0.79</td>
                  <td>0.85</td>
                  <td>72</td>
                </tr>
                <tr class="cat_stats">
                  <td>PILLOW</td>
                  <td>0.87</td>
                  <td>0.98</td>
                  <td>0.92</td>
                  <td>87</td>
                </tr>
                <tr class="cat_stats">
                  <td>PLANTER</td>
                  <td>0.88</td>
                  <td>0.99</td>
                  <td>0.93</td>
                  <td>80</td>
                </tr>
                <tr class="cat_stats">
                  <td>PORTABLE_ELECTRONIC_DEVICE_COVER</td>
                  <td>0.96</td>
                  <td>0.87</td>
                  <td>0.91</td>
                  <td>84</td>
                </tr>
                <tr class="cat_stats">
                  <td>RING</td>
                  <td>1.00</td>
                  <td>0.94</td>
                  <td>0.97</td>
                  <td>88</td>
                </tr>
                <tr class="cat_stats">
                  <td>RUG</td>
                  <td>0.98</td>
                  <td>0.97</td>
                  <td>0.97</td>
                  <td>90</td>
                </tr>
                <tr class="cat_stats">
                  <td>SAFETY_SUPPLY</td>
                  <td>0.89</td>
                  <td>0.84</td>
                  <td>0.86</td>
                  <td>83</td>
                </tr>
                <tr class="cat_stats">
                  <td>SANDAL</td>
                  <td>0.87</td>
                  <td>0.93</td>
                  <td>0.90</td>
                  <td>80</td>
                </tr>
                <tr class="cat_stats">
                  <td>SAUTE_FRY_PAN</td>
                  <td>0.96</td>
                  <td>0.95</td>
                  <td>0.96</td>
                  <td>83</td>
                </tr>
                <tr class="cat_stats">
                  <td>SCREEN_PROTECTOR</td>
                  <td>0.96</td>
                  <td>0.99</td>
                  <td>0.97</td>
                  <td>87</td>
                </tr>
                <tr class="cat_stats">
                  <td>SKIN_MOISTURIZER</td>
                  <td>0.91</td>
                  <td>0.89</td>
                  <td>0.90</td>
                  <td>87</td>
                </tr>
                <tr class="cat_stats">
                  <td>SOFA</td>
                  <td>0.79</td>
                  <td>0.86</td>
                  <td>0.82</td>
                  <td>86</td>
                </tr>
                <tr class="cat_stats">
                  <td>STOOL_SEATING</td>
                  <td>0.96</td>
                  <td>0.96</td>
                  <td>0.96</td>
                  <td>79</td>
                </tr>
                <tr class="cat_stats">
                  <td>STORAGE_BINDER</td>
                  <td>0.93</td>
                  <td>0.97</td>
                  <td>0.95</td>
                  <td>69</td>
                </tr>
                <tr class="cat_stats">
                  <td>STORAGE_HOOK</td>
                  <td>0.94</td>
                  <td>0.97</td>
                  <td>0.95</td>
                  <td>90</td>
                </tr>
                <tr class="cat_stats">
                  <td>SUITCASE</td>
                  <td>0.87</td>
                  <td>0.95</td>
                  <td>0.91</td>
                  <td>80</td>
                </tr>
                <tr class="cat_stats">
                  <td>TABLE</td>
                  <td>0.82</td>
                  <td>0.79</td>
                  <td>0.80</td>
                  <td>84</td>
                </tr>
                <tr class="cat_stats">
                  <td>TEA</td>
                  <td>0.87</td>
                  <td>0.96</td>
                  <td>0.91</td>
                  <td>70</td>
                </tr>
                <tr class="cat_stats">
                  <td><strong>Accuracy</strong></td>
                  <td colspan="4">0.88</td>
                </tr>
                <tr class="cat_stats">
                  <td><strong>Macro avg</strong></td>
                  <td>0.87</td>
                  <td>0.88</td>
                  <td>0.87</td>
                  <td>5167</td>
                </tr>
                <tr class="cat_stats">
                  <td><strong>Weighted avg</strong></td>
                  <td>0.88</td>
                  <td>0.88</td>
                  <td>0.87</td>
                  <td>5167</td>
                </tr>
              </tbody>
            </table>


            <button id="show-more-table-btn" onclick="showMoreStats()"
              style="margin-top: -20px; margin-bottom: 60px">...expandir</button>


            <h3 class="orange_title major">Modelo en acción</h3>
            <p style="margin-bottom: 20px">Se creó un espacio en HuggingFace Spaces para tener el modelo activo
              utilizando Gradio de forma constante, para poder ser utilizado en cualquier momento. Puedes usarlo aquí
              abajo, ¡pruébalo con una foto propia!</p>

            <div style="text-align: center;">
              <iframe allow="camera" src="https://nicolaspavon-amazon-classification.hf.space" frameborder="0"
                class="gradio"></iframe>
            </div>

            <p style="margin-bottom: 20px; margin-top: 10px;">Aquí dejo las categorías más frecuentemente accesibles (en
              mi opinión), pero puedes fotografiar cualquier objeto de <a class="a-custom" href="#categorias">las 65
                categorías</a> para probar el modelo.</p>
            <div class="category-group" style="width: 100%;">
              <i class="variable_2">COFFEE</i>
              <i class="variable_2">TEA</i>
              <i class="variable_2">BREAD</i>
              <i class="variable_2">DRINKING_CUP</i>
              <i class="variable_2">HEADPHONES</i>
              <i class="variable_2">CHARGING_ADAPTER</i>
              <i class="variable_2">SHOES</i>
              <i class="variable_2">PILLOW</i>
              <i class="variable_2">CHAIR</i>
              <i class="variable_2">WALL_ART</i>
              <i class="variable_2">LAMP</i>
              <i class="variable_2">RING</i>
              <i class="variable_2">HAT</i>
              <i class="variable_2">BACKPACK</i>
              <i class="variable_2">SUITCASE</i>
              <i class="variable_2">PLANTER</i>
              <i class="variable_2">WALLET</i>
            </div>
          </section>
        </div>
      </div>
      <div class="wrapper alt style4">
        <div class="inner">
          <section>
            <h3 class="orange_title major">Aspectos a mejorar</h3>
            <p>Como se observó en la etapa de análisis del dataset, una gran cantidad de imágenes de <i
                class="variable">RUG</i> contienen otros elementos como sillones, sillas, mesas, entre otros. Esto
              perjudica a la red, provocando que imágenes de sillones, por ejemplo, sean clasificadas erróneamente bajo
              la categoría <i class="variable">RUG</i>. Quitar estas imágenes "genéricas" del dataset mejoraría
              notablemente la performance.</p>
            <p>En el dataset también hay muchas imágenes que muestran la textura o el color del objeto en venta, lo cual
              no aporta al entrenamiento de la red y posiblemente cause problemas.</p>
            <p>La categoría <i class="variable">FURNITURE_COVER</i> es muy similar a categorías como <i
                class="variable">SOFA</i> o <i class="variable">CHAIR</i>, causando clasificaciones erróneas.</p>
            <p>Como se comentó en la etapa de <a class="a-custom" href="#inspeccion">inspección del dataset</a>, existen
              varias categorías que son muy genéricas o confundibles. Como era de esperar, al probar el modelo con
              objetos de <i class="variable">SUITCASE</i> y <i class="variable">LUGGAGE</i>, suele confundirse en la
              clasificación. De igual forma ocurre con <i class="variable">NUTRITIONAL_SUPPLEMENT</i> ↔ <i
                class="variable">VITAMINS</i> ↔ <i class="variable">HEALTH_PERSONAL_CARE</i>, las cuales suelen ser
              imágenes de frascos. En las <a class="a-custom" href="#score-table_2">estadísticas del modelo</a> se puede
              observar la mala performance que tienen estas categorías, debido a su similitud.</p>
            <p>Eliminar o unificar algunas de estas categorías mejoraría la mayoría de los problemas que tiene el
              modelo.</p>

            <h3 class="orange_title major">Cosas que no funcionaron</h3>
            <h5>Clustering de macro-categorias</h5>
            <p>En un principio, se asoció la mala performance del modelo a la gran cantidad de categorías. Por esta
              razón, se planteó la posibilidad de crear un modelo genérico encargado de clasificar dentro de 4-5
              macro-categorías, y luego aplicar otro submodelo para cada macro-categoría, encargado de identificar la
              categoría final. Para esto, incluso se utilizó una técnica de clustering similar a la utilizada en el
              balanceo del dataset, que agrupó las categorías similares para luego, a partir de estos grupos, generar
              las macro-categorías. A continuación, se puede observar el gráfico generado para la agrupación:
            </p>
            <div class="gtr-uniform home-images" style="margin-bottom: 10px">
              <span class=" image fit" style="margin: 0px;"><img src="images/ABO/class clustering.png" alt="" />
                <p style="margin-bottom: 0px; margin-top: 10px;"><i>Agrupaciones de categorias por similitud</i></p>
              </span>
            </div>
            <p>Como se puede observar, agrupó exitosamente categorías como <i class="variable">SOFA</i>, <i
                class="variable">RUG</i>, <i class="variable">CHAIR</i> y otras dentro de una posible macro-categoría <i
                class="variable">FURNITURE</i> (rama verde). De igual forma, ocurre con otras categorías similares.
            </p>
            <p>Si bien esta idea parecía prometedora, se observó que el modelo era capaz de trabajar exitosamente con
              las
              65 categorías, por lo que esta idea quedó obsoleta.
            </p>
            <h5>Imágenes en blanco y negro</h5>
            <p>Se intento pasar las imagenes a blanco y negro, ya que los colores no deberían hacer la diferencia entre
              una
              categoria u otra. sin embargo no se notó mejora, aunque quizás fue por un error de implementación.</p>
          </section>
        </div>
      </div>
      <div class="wrapper style2">
        <div class="inner">
          <section>
            <h2 class="white-big major">Conclusiones</h2>
            <p>En resumen, el desarrollo de este modelo nos permitió explorar estrategias para abordar problemas
              complejos de clasificación de imágenes, utilizando técnicas como transfer learning, fine-tuning,
              clustering y comparación de similitud de imágenes para balancear el dataset. A pesar de las limitaciones
              debido a la calidad y composición de los datos, logramos un modelo performante que demuestra la eficacia
              de una red bien ajustada sobre un conjunto de categorías específicas.
            </p>
            <p>

              El análisis de los resultados y la implementación de soluciones para problemas como el overfitting y la
              confusión entre categorías similares resaltan la importancia de una correcta selección y balanceo de datos
              para mejorar el rendimiento del modelo.
            </p>
            <p>
              Si bien aún existen áreas de mejora, los resultados obtenidos muestran el potencial de un enfoque
              incremental para el desarrollo de modelos de aprendizaje profundo. Esto subraya la importancia de la
              experimentación constante y del ajuste fino para optimizar el desempeño en problemas reales.
            </p>
            <p>
              ¡Gracias por leer y espero que este recorrido haya sido tan enriquecedor para ti como lo fue para mí al
              desarrollarlo!</p>

            <p>Tienes alguna sugerencia o comentario? Déjamelo saber aquí abajo!</p>
          </section>
          <section id="contact-form">
            <div>
              <h3 class="orange_title major">Feedback</h3>
              <form id="feedbackForm" action="https://formspree.io/f/xyzygapb" method="POST">
                <div class="fields">
                  <div class="field half">
                    <label for="name">Nombre</label>
                    <input type="text" name="name" id="name" placeholder="Your Name" required>
                  </div>
                  <div class="field half second">
                    <label for="email">Email</label>
                    <input type="email" name="email" id="email" placeholder="Your Email" required>
                  </div>
                  <div class="field">
                    <label for="message">Mensaje</label>
                    <textarea name="message" id="message" rows="6" placeholder="Your Message" required></textarea>
                  </div>
                  <div class="field">
                    <button type="submit" class="button">Send Message</button>
                  </div>
                </div>
              </form>
            </div>
          </section>

        </div>
      </div>
    </section>

    <!-- Footer -->
    <section id="footer"></section>
  </div>

  <!-- Scripts -->
  <script src="assets/js/jquery.min.js"></script>
  <script src="assets/js/jquery.scrollex.min.js"></script>
  <script src="assets/js/browser.min.js"></script>
  <script src="assets/js/breakpoints.min.js"></script>
  <script src="assets/js/util.js"></script>
  <script src="assets/js/main.js"></script>
  <script src="scripts/menu.js"></script>
  <script src="scripts/footer.js"></script>

  <script>
    function applyColorToCell() {
      const table = document.getElementById('score-table');
      const rows = table.getElementsByTagName('tr');

      for (let i = 1; i < rows.length; i++) {
        const cells = rows[i].getElementsByTagName('td');

        const accuracy = parseFloat(cells[6].innerText);
        const loss = parseFloat(cells[7].innerText);
        const valAccuracy = parseFloat(cells[8].innerText);
        const valLoss = parseFloat(cells[9].innerText);

        // For accuracy and val_accuracy (higher is better)
        cells[6].style.backgroundColor = getGreenToRedGradient(accuracy, true);
        cells[8].style.backgroundColor = getGreenToRedGradient(valAccuracy, true);

        // For loss and val_loss (lower is better)
        cells[7].style.backgroundColor = getGreenToRedGradient(loss, false);
        cells[9].style.backgroundColor = getGreenToRedGradient(valLoss, false);
      }
    }

    function applyColorToCell_2() {
      const table = document.getElementById('score-table_2');
      const rows = table.getElementsByTagName('tr');
      console.log(rows.length)


      for (let i = 1; i < rows.length; i++) {
        const cells = rows[i].getElementsByTagName('td');
        console.log(cells)

        const precision = parseFloat(cells[1].innerText);
        const recall = parseFloat(cells[2].innerText);
        const f1 = parseFloat(cells[3].innerText);

        // For accuracy and val_accuracy (higher is better)
        cells[1].style.backgroundColor = getGreenToRedGradient(precision, true);
        cells[2].style.backgroundColor = getGreenToRedGradient(recall, true);
        cells[3].style.backgroundColor = getGreenToRedGradient(f1, true);
      }
    }

    function getGreenToRedGradient(value, higherIsBetter) {
      const colors = [
        { r: 0, g: 128, b: 0 },     // Green
        { r: 85, g: 170, b: 0 },    // Yellowgreen
        { r: 255, g: 255, b: 0 },   // Yellow
        { r: 255, g: 165, b: 0 },   // Orange
        { r: 255, g: 0, b: 0 },     // Red
        { r: 0, g: 0, b: 0 }        // Black
      ];

      // Adjust ratio for whether higher or lower is better
      let ratio = !higherIsBetter ? value : 1 - value;
      const step = 1 / (colors.length - 1);
      const index = Math.min(Math.floor(ratio / step), colors.length - 2);
      const color1 = colors[index];
      const color2 = colors[index + 1];

      const t = (ratio - index * step) / step;
      const r = Math.round(color1.r * (1 - t) + color2.r * t);
      const g = Math.round(color1.g * (1 - t) + color2.g * t);
      const b = Math.round(color1.b * (1 - t) + color2.b * t);

      return `rgb(${r}, ${g}, ${b}, 0.8)`; // Added opacity (0.8) to the colors
    }



    // Call the function to apply colors on page load
    applyColorToCell();
    applyColorToCell_2();
  </script>

</body>

</html>